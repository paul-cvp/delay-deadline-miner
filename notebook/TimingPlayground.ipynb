{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b055db3-3c98-4b8d-9ea6-0a577be326d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa87c87-7462-449e-8af4-1d3a19def588",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys                                             # Module to see files and folders in directories\n",
    "\n",
    "import pm4py\n",
    "\n",
    "from fitter import Fitter, get_common_distributions\n",
    "from pm4py.objects.conversion.log import converter as log_converter\n",
    "from pm4py.algo.filtering.log.attributes import attributes_filter\n",
    "from pm4py.objects.log.util import dataframe_utils\n",
    "from itertools import chain, combinations\n",
    "from scipy.stats import expon, lognorm, norm, poisson, uniform\n",
    "import numpy as np                     \n",
    "import matplotlib as mpl                # Matlab like syntax for linear algebra and functions\n",
    "import matplotlib.pyplot as plt                        # Plots and figures like you know them from Matlab\n",
    "import seaborn as sns                                  # Make the plots nicer to look at\n",
    "from iminuit import Minuit,cost                             # The actual fitting tool, better than scipy's\n",
    "from scipy import stats, math\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append('External_Functions') # TODO: use your own folder reference\n",
    "from ExternalFunctions import Chi2Regression\n",
    "from ExternalFunctions import nice_string_output, add_text_to_ax # useful functions to print fit results on figure\n",
    "\n",
    "r = np.random                         # Random generator\n",
    "r.seed(1)                            # Set a random seed (but a fixed one - more on that later.)\n",
    "\n",
    "save_plots = False\n",
    "\n",
    "# Set som plotting standards:\n",
    "font = {'family' : 'serif',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 16}\n",
    "mpl.rc('font', **font)\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d2afda-840f-4894-bda5-3298a79d9ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from distfit import distfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf20fe63-07b4-4d28-8d11-2d485c00eafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dcr_timing as dcrt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38041eff-cf8b-4fb2-9d94-6049d9590f85",
   "metadata": {},
   "source": [
    "## Element-wise difference matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5314232-4c65-46d0-b2a5-c4d619c3c37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Python3 code to demonstrate working of\n",
    "# Element-wise Matrix Difference\n",
    "# Using loop + zip()\n",
    " \n",
    "# initializing lists\n",
    "test_list1 = [[2, 4, 5], [5, 4, 2], [1, 2, 3]]\n",
    "test_list2 = [[6, 4, 6], [9, 6, 3], [7, 5, 4]]\n",
    " \n",
    "# printing original lists\n",
    "print(\"The original list 1 is : \" + str(test_list1))\n",
    "print(\"The original list 2 is : \" + str(test_list2))\n",
    "def element_wise_difference_matrix(list1,list2):\n",
    "# using list comprehension to perform task in one line\n",
    "    return [[ele2 - ele1 for ele1, ele2 in zip(sub1, sub2)]\n",
    "           for sub1, sub2 in zip(list1, list2)]\n",
    " \n",
    "# printing result\n",
    "print(\"The Matrix Difference : \" + str(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deea7234-3bed-414d-8e58-4516122a2a56",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b28cf16-86f7-474c-b285-b35a04e9fad4",
   "metadata": {},
   "source": [
    "## Pseudocode\n",
    "\n",
    "Function(log,array(Rule,Event1,Event2)):\n",
    "    result = array()\n",
    "    for each trace in Log do:\n",
    "        for each (Rule, Event1, Event2) in T_tuple do:\n",
    "            scoped_log <- create a subset of traces from log that contain both event1 and event2\n",
    "            only_event1_event2_log <- from each trace create a subset of scoped_log that only has data related to event1 and event2\n",
    "            sort(only_event1_event2) <- sort by case:concept:name and time:timestamp\n",
    "            if Rule is DELAY then\n",
    "                delta = timestep_event2 - timestep_first_preceeding_event1\n",
    "            else Rule is DEADLINE\n",
    "                delta = MAX(|timestep_between_consecutve_event1| or (timestep_event2-timestep_first_preceeding_event1))\n",
    "            result.append(timing_data)\n",
    "     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf7aaae-e230-43fc-93f1-c24cceca1426",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_with_pair(event_log,e1,e2):\n",
    "    first_e1 = event_log[event_log['concept:name']==e1].groupby('case:concept:name')[['case:concept:name','time:timestamp']].first().reset_index(drop=True)\n",
    "    subset_is_in = first_e1.merge(event_log,on='case:concept:name',how='inner',suffixes=('_e1', ''))\n",
    "    cids = subset_is_in[((subset_is_in['time:timestamp_e1']<subset_is_in['time:timestamp']) & (subset_is_in['concept:name']==e2))]['case:concept:name'].unique()\n",
    "    return event_log[event_log['case:concept:name'].isin(cids)].copy(deep=True)\n",
    "\n",
    "def get_max_for_response(temp_df):\n",
    "    '''\n",
    "    This method is a way to find the max response (deadline).\n",
    "    Within a trace it keeps track of the max delta between either (e1,e1) or (e1,e2) pairs.\n",
    "    When it reaches a (e1,e2) pair it updates the delta on that row with the max delta found in preceeding pairs.\n",
    "    This means that it will either take the current row delta because this is the only occurence of (e1,e2)\n",
    "    or it will take a delta from a previous pair of (e1,e1) and assign it to that pair (e1,e2)\n",
    "    :param temp_df: this is a dataframe with only the event pairs (e1 and e2) where at least 1 e1 preceeds an e2 for all traces\n",
    "    :return:\n",
    "    '''\n",
    "    cids = temp_df['case:concept:name'].unique()\n",
    "    for cid in cids:\n",
    "        max_days = 0\n",
    "        for index,row in temp_df[temp_df['case:concept:name']==cid].iterrows():\n",
    "            max_days = max(max_days,row['delta'])\n",
    "            if row['concept:name']!=row['concept:name:to']:\n",
    "                temp_df.loc[index,'delta'] = max_days\n",
    "                max_days = 0\n",
    "    return temp_df\n",
    "\n",
    "def get_delta_between_events(filtered_df, event_pair, rule):\n",
    "\n",
    "    filtered_df['time:timestamp'] = pd.to_datetime(filtered_df['time:timestamp'], utc=True)\n",
    "    filtered_df = filtered_df[(filtered_df['concept:name']==event_pair[1]) |\n",
    "                               (filtered_df['concept:name']==event_pair[0])].sort_values(['case:concept:name','time:timestamp'])\n",
    "    temp_df = pd.concat([filtered_df, filtered_df.groupby('case:concept:name').shift(-1)\n",
    "                         .rename({'concept:name':'concept:name:to','time:timestamp':'time:timestamp:to'},axis=1)],axis=1)\n",
    "\n",
    "    temp_df['delta'] = (temp_df['time:timestamp:to'] - temp_df['time:timestamp']).dt.days\n",
    "\n",
    "    if rule=='RESPONSE':\n",
    "        temp_df = get_max_for_response(temp_df)\n",
    "    temp_df = temp_df[(temp_df['concept:name']==event_pair[0]) & (temp_df['concept:name:to']==event_pair[1])]\n",
    "    data = temp_df['delta'].values\n",
    "    return data\n",
    "\n",
    "def create_timing_input_dict(model):\n",
    "    with open(model) as file:\n",
    "        lines = file.readlines()\n",
    "        lines = [line.strip() for line in lines]\n",
    "\n",
    "    events = []\n",
    "    conditions = []\n",
    "    responses = []\n",
    "    #includes = []\n",
    "    #excludes = []\n",
    "    for line in lines:\n",
    "        temp = line.split(',')\n",
    "        if temp[0] == 'EVENT':\n",
    "            events.append(temp[1])\n",
    "        elif temp[0] == 'CONDITION':\n",
    "            conditions.append(temp[1:])\n",
    "        elif temp[0] == 'RESPONSE':\n",
    "            responses.append(temp[1:])\n",
    "\n",
    "    timing_input_dict = {'CONDITION' : conditions,\n",
    "                         'RESPONSE': responses}\n",
    "    return timing_input_dict\n",
    "\n",
    "def get_timings(log,timing_input_dict):\n",
    "    if isinstance(log,pd.DataFrame):\n",
    "        event_log = log\n",
    "    else:\n",
    "        event_log = log_converter.apply(log, variant=log_converter.Variants.TO_DATA_FRAME)\n",
    "    res = {}\n",
    "\n",
    "    for rule, event_pairs in timing_input_dict.items():\n",
    "        #print(rule)\n",
    "        for event_pair in event_pairs:\n",
    "            filtered_df = get_log_with_pair(event_log,event_pair[0],event_pair[1]) #= pm4py.filter_between(log,event_pair[0],event_pair[1])\n",
    "            data = get_delta_between_events(filtered_df,event_pair,rule)\n",
    "            #print(event_pair)\n",
    "            res[(rule,event_pair[0],event_pair[1])] = data\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334158fc-3cd1-4ad2-b773-19bc25ad7cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "cids = [1,1,1,1,1,1,\n",
    "        2,2,2,2,2,\n",
    "        3,3,3,3,3,3,3,3,3,3,\n",
    "        4,4,4,4,4,4,4,4,4,4,4,4,4]\n",
    "events = ['A','B','C','D','E','F',\n",
    "          'A', 'B', 'E', 'F' ,'C',\n",
    "          'A', 'B', 'F', 'C', 'B', 'C', 'B', 'E', 'F', 'C',\n",
    "          'B','B','B','Z','B','C','B','A','C','Z','C','C','B']\n",
    "timestamps = [pd.to_datetime('2021-10-01'),pd.to_datetime('2021-10-02'),pd.to_datetime('2021-10-03'),\n",
    "                      pd.to_datetime('2021-10-04'),pd.to_datetime('2021-10-05'),pd.to_datetime('2021-10-06'),\n",
    "                     pd.to_datetime('2021-10-01'),pd.to_datetime('2021-10-02'),pd.to_datetime('2021-10-03'),\n",
    "                      pd.to_datetime('2021-10-04'),pd.to_datetime('2021-10-05'),\n",
    "                     pd.to_datetime('2021-10-01'),pd.to_datetime('2021-10-02'),pd.to_datetime('2021-10-03'),\n",
    "                      pd.to_datetime('2021-10-04'),pd.to_datetime('2021-10-05'),pd.to_datetime('2021-10-06'),pd.to_datetime('2021-10-07'),\n",
    "                      pd.to_datetime('2021-10-08'),pd.to_datetime('2021-10-09'),pd.to_datetime('2021-10-10'),\n",
    "                     pd.to_datetime('2020-01-01'),pd.to_datetime('2021-02-02'),pd.to_datetime('2021-02-03'),\n",
    "                      pd.to_datetime('2021-02-04'),pd.to_datetime('2021-02-05'),pd.to_datetime('2021-10-06'),\n",
    "                      pd.to_datetime('2021-10-07'),pd.to_datetime('2021-10-08'),pd.to_datetime('2021-10-09'),\n",
    "                      pd.to_datetime('2021-10-10'),pd.to_datetime('2021-10-11'),pd.to_datetime('2025-10-11'),pd.to_datetime('2040-10-11')]\n",
    "test_log_dict = {\n",
    "    'case:concept:name':cids,\n",
    "    'concept:name':events,\n",
    "    'time:timestamp':timestamps\n",
    "}\n",
    "\n",
    "test_tid = {\n",
    "    'CONDITION': [['B','C']],\n",
    "    'RESPONSE': [['B','C']]\n",
    "}\n",
    "\n",
    "test_log_df = pd.DataFrame(test_log_dict)\n",
    "test_event_log = log_converter.apply(test_log_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311f094d-e989-4561-b292-229271bc815c",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_timings(test_log_df,test_tid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52277a8d-8eb5-4749-b755-5f0c5d579a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#print(get_timings(test_log_df[test_log_df['case:concept:name']==4],test_tid))\n",
    "res = {}\n",
    "for i in range(1,5):\n",
    "    k = get_timings(test_log_df[test_log_df['case:concept:name']==i],test_tid)\n",
    "    for i,v in k.items():\n",
    "        if i in res:\n",
    "            res[i] = np.append(res[i],v)\n",
    "        else:\n",
    "            res[i] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff789d3-de96-487b-b3a6-cec84ea6f492",
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189f1331-f8ee-4b5a-901a-5c5d3aeb528c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Util methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e99ef0-3f0a-48f2-b308-8717fb7222d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timings(log,timing_input_dict):\n",
    "        if isinstance(log,pd.DataFrame):\n",
    "            event_log = log\n",
    "        else:\n",
    "            event_log = log_converter.apply(log, variant=log_converter.Variants.TO_DATA_FRAME)\n",
    "        res = {}\n",
    "\n",
    "        for rule, event_pairs in timing_input_dict.items():\n",
    "            #print(rule)\n",
    "            for event_pair in event_pairs:\n",
    "                filtered_df = pm4py.filter_between(log,event_pair[0],event_pair[1])\n",
    "                \n",
    "                filtered_df['time:timestamp'] = pd.to_datetime(filtered_df['time:timestamp'], utc=True)\n",
    "                filtered_df = filtered_df[(filtered_df['concept:name']==event_pair[1]) |\n",
    "                                   (filtered_df['concept:name']==event_pair[0])].sort_values(['case:concept:name','time:timestamp'])\n",
    "                temp_df = pd.concat([filtered_df, filtered_df.groupby('case:concept:name').shift(-1)\n",
    "                             .rename({'concept:name':'concept:name:to','time:timestamp':'time:timestamp:to'},axis=1)],axis=1)\n",
    "\n",
    "                temp_df['delta'] = (temp_df['time:timestamp:to'] - temp_df['time:timestamp']).dt.days\n",
    "\n",
    "                if rule=='RESPONSE':\n",
    "                    cid=None\n",
    "                    max_days = 0\n",
    "                    for index,row in temp_df.iterrows():\n",
    "                        if cid == row['case:concept:name']:\n",
    "                            max_days = max(max_days,row['delta'])\n",
    "                            if row['concept:name']!=row['concept:name:to']:\n",
    "                                #print(max_days,' row: ',row)\n",
    "                                temp_df.loc[index,'delta'] = max_days\n",
    "                                max_days = 0\n",
    "                        else:\n",
    "                            max_days = 0\n",
    "                        cid = row['case:concept:name']\n",
    "                        \n",
    "                temp_df = temp_df[(temp_df['concept:name']==event_pair[0]) & (temp_df['concept:name:to']==event_pair[1])]\n",
    "                data = temp_df['delta'].values\n",
    "                #print(event_pair)\n",
    "                res[(rule,event_pair[0],event_pair[1])] = data\n",
    "\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75966226-26f3-4037-a19c-e159fa8edf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freedman_diaconis_rule(data):\n",
    "    \"\"\"rule to find the bin width and number of bins from data\"\"\"\n",
    "    if (stats.iqr(data)>0):\n",
    "        bin_width = 2*stats.iqr(data) / len(data)**(1/3)\n",
    "        Nbins = int(np.ceil((data.max()-data.min())/bin_width))\n",
    "        return Nbins, bin_width\n",
    "    else:\n",
    "        return 100, 0\n",
    "\n",
    "def uniform_pdf(x,a,b):\n",
    "    if a<=x and x<=b:\n",
    "        return 1/(b-a)\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def exp_pdf(x, tau):\n",
    "    \"\"\"Exponential with lifetime tau\"\"\"\n",
    "    return 1.0 / tau * np.exp(-x/tau)\n",
    "\n",
    "def gauss_pdf(x, mu, sigma) :\n",
    "    \"\"\"Gaussian\"\"\"\n",
    "    return 1.0 / np.sqrt(2*np.pi) / sigma * np.exp( -0.5 * (x-mu)**2 / sigma**2)\n",
    "\n",
    "def N_gauss_pdf(x, N, mu, sigma) :\n",
    "    \"\"\"Gaussian\"\"\"\n",
    "    return N*binwidth*gauss_pdf(x, mu, sigma)\n",
    "\n",
    "def log_gauss_pdf(x,mu,sigma):\n",
    "    return 1.0 / np.sqrt(2*np.pi) / (sigma*x) * np.exp(-0.5 * (np.log(x)-mu)**2 / sigma**2)\n",
    "\n",
    "def N_log_gauss_pdf(x,N,mu,sigma):\n",
    "    return N*binwidth*log_gauss_pdf(x,mu,sigma)\n",
    "\n",
    "def double_gaussian(x,N,mu,sigma,N2,mu2,sigma2):\n",
    "    return N*binwidth*gauss_pdf(x,mu,sigma) + N2*binwidth*gauss_pdf(x,mu2,sigma2)\n",
    "\n",
    "def triple_gaussian(x,N,mu,sigma,N2,mu2,sigma2,N3,mu3,sigma3):\n",
    "    return N*binwidth*gauss_pdf(x,mu,sigma) + N2*binwidth*gauss_pdf(x,mu2,sigma2) + N3*binwidth*gauss_pdf(x,mu3,sigma3)\n",
    "\n",
    "def triple_gauss_gauss_log(x,N,mu,sigma,N2,mu2,sigma2,N3,mu3,sigma3):\n",
    "    return N*binwidth*gauss_pdf(x,mu,sigma) + N2*binwidth*gauss_pdf(x,mu2,sigma2) + N3*binwidth*log_gauss_pdf(x,mu3,sigma3)\n",
    "\n",
    "# def triple_gauss_log_log(x,N,mu,sigma,N2,mu2,sigma2,N3,mu3,sigma3):\n",
    "#     return N*binwidth*gauss_pdf(x,mu,sigma) + N2*binwidth*log_gauss_pdf(x,mu2,sigma2) + N3*binwidth*log_gauss_pdf(x,mu3,sigma3)\n",
    "\n",
    "def triple_gauss_log_log(x,N,mu,sigma,N2,mu2,sigma2,N3,mu3,sigma3):\n",
    "    if x<61:\n",
    "        return N*binwidth*gauss_pdf(x,mu,sigma)\n",
    "    else:\n",
    "        return N2*binwidth*log_gauss_pdf(x,mu2,sigma2) + N3*binwidth*log_gauss_pdf(x,mu3,sigma3)\n",
    "\n",
    "def double_log_gaussian(x,N,mu,sigma,N2,mu2,sigma2,binwidth):\n",
    "    return N*binwidth*log_gauss_pdf(x,mu,sigma) + N2*binwidth*log_gauss_pdf(x,mu2,sigma2)\n",
    "\n",
    "def double_log_gaussian_exp(x,N_exp, tau,N,mu,sigma,N2,mu2,sigma2,binwidth):\n",
    "    return N_exp*binwidth*exp_pdf(x,tau) + N*binwidth*log_gauss_pdf(x,mu,sigma) + N2*binwidth*log_gauss_pdf(x,mu2,sigma2)\n",
    "\n",
    "def double_gaussian_exp(x,N_exp, tau,N,mu,sigma,N2,mu2,sigma2):\n",
    "    return N_exp*binwidth*exp_pdf(x,tau) + N*binwidth*gauss_pdf(x,mu,sigma) + N2*binwidth*gauss_pdf(x,mu2,sigma2)\n",
    "\n",
    "def gaus_log_gauss_exp(x,N_exp, tau,N,mu,sigma,N2,mu2,sigma2):\n",
    "    return N_exp*binwidth*exp_pdf(x,tau) + N*binwidth*gauss_pdf(x,mu,sigma) + N2*binwidth*log_gauss_pdf(x,mu2,sigma2)\n",
    "\n",
    "def fit_minuit(function_to_fit, initial_values_dict, x, y, sy, err_def=1):\n",
    "    \"\"\"Fit any defined function using least squares\n",
    "    NOTE: All fixed parameters that are part of the 'function_to_fit'\n",
    "    need to be initialized before this method call\n",
    "    \n",
    "    Parameters:\n",
    "    function_to_fit: the function to fit the data to can be anything (gaussian, exp, exp+gauss,a+b)\n",
    "    initial_values_dict: a dictionary of key value pairs that are the initial input to the function_to_fit\n",
    "    x: input training data\n",
    "    y: result training data\n",
    "    sy: errors on the output (if data is binned errors are poisson)\n",
    "    err_def: 1: ls fit 0.5: likelihood fit\n",
    "   \n",
    "    returns: Chi2, Ndof, Prob\n",
    "    \"\"\"\n",
    "    Minuit.print_level = 1\n",
    "    ls_fit = cost.LeastSquares(x, y, sy, function_to_fit)\n",
    "    \n",
    "    \n",
    "    minuit_fit = Minuit(ls_fit, **initial_values_dict)\n",
    "    if 'binwidth' in initial_values_dict.keys():\n",
    "        minuit_fit.fixed['binwidth'] = True\n",
    "    minuit_fit.migrad()       # Perform the actual fit\n",
    "\n",
    "    ls_fit = minuit_fit.fval\n",
    "    return minuit_fit\n",
    "\n",
    "def fit_chi2_minuit(function_to_fit, initial_values_dict, x, y, sy, err_def=1):\n",
    "    \"\"\"Fit any defined function using Chi2\n",
    "    NOTE: All fixed parameters that are part of the 'function_to_fit'\n",
    "    need to be initialized before this method call\n",
    "    \n",
    "    Parameters:\n",
    "    function_to_fit: the function to fit the data to can be anything (gaussian, exp, exp+gauss,a+b)\n",
    "    initial_values_dict: a dictionary of key value pairs that are the initial input to the function_to_fit\n",
    "    x: input training data\n",
    "    y: result training data\n",
    "    sy: errors on the output (if data is binned errors are poisson)\n",
    "    err_def: 1: chi2 fit 0.5: likelihood fit\n",
    "   \n",
    "    returns: Chi2, Ndof, Prob\n",
    "    \"\"\"\n",
    "    Minuit.print_level = 1\n",
    "    chi2_fit = Chi2Regression(function_to_fit, x, y, sy)\n",
    "    chi2_fit.errordef = 1\n",
    "    minuit_fit = Minuit(chi2_fit, **initial_values_dict)   \n",
    "    minuit_fit.migrad()       # Perform the actual fit\n",
    "\n",
    "    Chi2_fit = minuit_fit.fval\n",
    "    Ndof_fit = len(x) - len(initial_values_dict)\n",
    "    Prob_fit = stats.chi2.sf(Chi2_fit, Ndof_fit)\n",
    "    Reduced_chi2 = minuit_fit.fval / (len(x) - minuit_fit.nfit) # should be roughly 1 for a good fit\n",
    "    return minuit_fit, {'Chi2':Chi2_fit,'Ndof':Ndof_fit,'Prob':Prob_fit,'Reduced chi2':Reduced_chi2}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2ab3b7-bc92-4062-809f-798ada757e81",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Timing DCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842d8209-fcd8-4d21-9e90-f9328997aa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = '/c/Data/road_traffic_fine/Road_Traffic_Fine_Management_Process.xes'\n",
    "model = '/c/Projects/DisCoveR-JS/models/road_traffic_fine'\n",
    "timing_results = '../models/timing_information.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1205692-feaf-4fd5-b910-8d5bccbc30b5",
   "metadata": {},
   "source": [
    "### Creating timing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786ca6e6-d3b9-4627-bc44-bfd1cb9c491d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dcrt.create_timings(dataset,model,timing_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ddd773-1d2e-4e41-b6f5-ec75ec394669",
   "metadata": {},
   "source": [
    "Only event_pair[1] -> first occurence of event_pair[0] in the past in terms of the delta difference\n",
    "Example trace:\n",
    "\n",
    "A1 A2 B1 A3 B2 B3\n",
    "        \n",
    "    CONDITION: See a B take first preceding A\n",
    "        (A2, B1) (A3, B2) \n",
    "        !THIS does not count: (A3 B3)\n",
    "    RESPONSE\n",
    "        MAX((A1,A2) and (A2, B1)) (A3, B2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b7015e-2474-4481-b54a-e51cfbb4c3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_2 = pm4py.read_xes('/c/Data/bpi/2015/BPIC15_1.xes')\n",
    "event_log_2 = log_converter.apply(log_2,variant=log_converter.Variants.TO_DATA_FRAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4703cc-9732-475f-b090-a59f996ed6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_log_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a880fc50-5f76-4322-a3c7-7615474d94ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_el2 = event_log_2[['case:concept:name','time:timestamp','concept:name','activityNameEN']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bf0592-9706-4d0a-8735-bb95d4081e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_el2[subset_el2['concept:name'].isin(['10_UOV_170','12_AP_UOV_020_1'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d920f5-b47f-465f-b8ae-773b93564817",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(event_log_2['concept:name'].unique()) == len(event_log_2['activityNameEN'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace6896e-900d-4e7c-9e82-79db7f912992",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(event_log_2['concept:name'].unique()))\n",
    "print(len(event_log_2['activityNameEN'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f9ebf9-fac0-4b6d-b2df-1b180047c4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_log_2[['concept:name','activityNameEN']].groupby(['concept:name','activityNameEN']).size().reset_index().rename(columns={0:'count'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0207e6ef-8c69-4893-bd8f-51d14e5046cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51398e38-8ed7-4ad0-a2a6-0d6035bf886b",
   "metadata": {},
   "outputs": [],
   "source": [
    "log = pm4py.read_xes(dataset)\n",
    "event_log = log_converter.apply(log, variant=log_converter.Variants.TO_DATA_FRAME)\n",
    "event_log['time:timestamp'] = pd.to_datetime(event_log['time:timestamp'], utc=True)\n",
    "activities = attributes_filter.get_attribute_values(log, \"concept:name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010df04e-b3f6-4669-864f-cbfc10b246b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_timings = pd.read_csv(timing_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e66821-64bc-4a6a-8b33-6a9b473e1c8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_timings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafc0cca-936b-4819-9f6e-fcc34d35b2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_log[['case:concept:name','concept:name','time:timestamp']].sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e049b274-f3ad-4dab-b83b-c1532aee0199",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nbins = 100\n",
    "xmin = 0\n",
    "xmax = 800\n",
    "#binwidth = (xmax-xmin)/Nbins\n",
    "total_plots = len(all_timings)\n",
    "\n",
    "data_dict = {}\n",
    "\n",
    "# only loop through timings where there are more than Nbins data points\n",
    "for i, row in all_timings[all_timings['cases_count']>Nbins].iterrows():\n",
    "    temp_df = pm4py.filter_between(log, row[1], row[2])\n",
    "    delta = dcrt.get_delta_between_events(temp_df,[row[1],row[2]],row[0])\n",
    "    data = delta\n",
    "    Nbins, binwidth = freedman_diaconis_rule(data)\n",
    "    # data for chi2 fit\n",
    "    counts, bin_edges = np.histogram(data,bins=Nbins,range=(xmin,xmax))\n",
    "    # take only non empty bins, that's why counts>0\n",
    "    x = (bin_edges[1:][counts>0] + bin_edges[:-1][counts>0])/2\n",
    "    y = counts[counts>0]\n",
    "    sy = np.sqrt(counts[counts>0])   # NOTE: We (naturally) assume that the bin count is Poisson distributed.\n",
    "        \n",
    "    data_dict[i] = [data,Nbins,x,y,sy,row,binwidth]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36738b4-ea23-4a7d-84ac-d37f313381fd",
   "metadata": {},
   "source": [
    "# Fit each rule with the right distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce0cf94-6a1d-42be-8bf9-7e82809fc56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boxplot_values(data):\n",
    "    median = np.median(data)\n",
    "    upper_quartile = np.percentile(data, 75)\n",
    "    lower_quartile = np.percentile(data, 25)\n",
    "\n",
    "    iqr = upper_quartile - lower_quartile\n",
    "    upper_whisker = data[data<=upper_quartile+1.5*iqr].max()\n",
    "    lower_whisker = data[data>=lower_quartile-1.5*iqr].min()\n",
    "    return (lower_whisker,lower_quartile,median,upper_quartile,upper_whisker,iqr)\n",
    "\n",
    "def get_histogram_values(data,Nbins):\n",
    "    hist,bins = np.histogram(data,bins=Nbins)\n",
    "    return (hist,bins)\n",
    "\n",
    "def get_best_fit_simple_distribution():\n",
    "    return None\n",
    "    \n",
    "def get_best_fit_advanced_distribution():\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96f99af-d2bf-4d33-a8f4-c2d1d6544964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_points(func_to_fit,func_params,N_samples,max_sample_y,xmin,xmax):\n",
    "    x_sampled = np.zeros(N_samples)\n",
    "    y_sampled = np.zeros(N_samples)\n",
    "    Ntry = 0\n",
    "    for i in range(N_samples):\n",
    "        while True:\n",
    "            Ntry += 1\n",
    "            sample_y = r.uniform(0,max_sample_y)\n",
    "            sample_x = r.uniform(xmin,xmax)\n",
    "            if sample_y < func_to_fit(sample_x,*func_params):\n",
    "                break\n",
    "        x_sampled[i] = sample_x\n",
    "        y_sampled[i] = sample_y\n",
    "    return x_sampled, y_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ff8d57-3504-4ab5-b5b7-73636698b26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "timing_results = pd.DataFrame(columns=['Rule','EventFrom','EventTo','Function','Parameters'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a269366b-055b-48d0-9ee1-3150fd5c691d",
   "metadata": {},
   "source": [
    "## 0: CONDITION   ['Create Fine', 'Send Fine'] 83232"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1686285-e612-4c47-bde3-b059392ab565",
   "metadata": {},
   "outputs": [],
   "source": [
    "data,Nbins,x,y,sy,row,binwidth = data_dict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af85f974-517b-4717-b56a-0c04974a6724",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1b87a7-6b25-4a71-82c4-815149d653f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9387b06-8166-4d1f-aeff-f579525924a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c384f9d-2867-4327-b55a-43a75c6839b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e34bf1-8f23-4e3e-9488-9039412bd45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Rule {row[0]}: {row[1]} -> {row[2]}')\n",
    "f = Fitter(data, distributions=get_common_distributions(),xmax=800,timeout=2*60,bins=Nbins)\n",
    "f.fit()\n",
    "res = f.summary(plot=False)\n",
    "fitter_best_fit = res.iloc[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d3adb7-257c-4f66-8f5f-e158e4c437e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5fc231-dae9-4ccc-8a34-d2d2e1472283",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.get_best()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c08beb9-4984-4e76-b46e-5ad727d95a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(f.get_best()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dca1c4-c3d8-43bd-b816-7ca54f55df52",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,5))\n",
    "fig.set_label(f'Rule {row[0]}: {row[1]} -> {row[2]}')\n",
    "f.hist()\n",
    "f.plot_pdf()\n",
    "plt.savefig(f'Rule {row[0]} - {row[1]} - {row[2]}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2975d83-00a8-4189-b424-35959ce3744c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = distfit(distr='popular') #full, popular, or a specific name\n",
    "dist.fit_transform(data)\n",
    "distfit_best_fit = dist.summary.iloc[0]['distr']\n",
    "fig, ax = plt.subplots(figsize=(16,5))\n",
    "dist.plot()\n",
    "#dist.plot_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3815a2cb-acae-4566-8d14-9867fe0450c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fitter_best_fit)\n",
    "print(distfit_best_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e10fbec-709a-4302-95f7-f5fa455613eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,5))\n",
    "counts, bins, bars = ax.hist(data, bins=Nbins, range=(xmin,xmax), histtype='step', density=False, alpha=1, color='g',label='Binned Duration Data')\n",
    "ax.errorbar(x, y, yerr=sy, xerr=0.0, label='Binned data uncertainty', fmt='.k',  ecolor='k', elinewidth=1, capsize=1, capthick=1)\n",
    "\n",
    "initial_values_dict = {\n",
    "    'N_exp':10000,\n",
    "    'tau': 1/np.e,\n",
    "    'N': 2000,\n",
    "    'mu': np.log(50),\n",
    "    'sigma': np.log(10),\n",
    "    'N2': 1000,\n",
    "    'mu2': np.log(140),\n",
    "    'sigma2': np.log(10)\n",
    "}\n",
    "func_to_fit = double_log_gaussian_exp\n",
    "minuit_fit, fit_info = fit_minuit(func_to_fit,initial_values_dict,x,y,sy)\n",
    "\n",
    "pred_y = []\n",
    "for k in x:\n",
    "    pred_y.append(func_to_fit(k, *minuit_fit.values[:]))\n",
    "pred_y = np.array(pred_y)\n",
    "ax.plot(x, pred_y, '-r',label='chi2 fit')     # Note how we can \"smartly\" input the fit values!\n",
    "\n",
    "\n",
    "d = {\n",
    " 'Rule':      row[0],\n",
    " 'Event from':      row[1],\n",
    " 'Event to':     row[2],\n",
    "}\n",
    "to_print = {}\n",
    "pm = u\"\\u00B1\"\n",
    "for k,v in minuit_fit.values.to_dict().items():\n",
    "    to_print[k] = f'{v:.2f}'+pm+f'{minuit_fit.errors.to_dict()[k]:.2f}'\n",
    "d = {**d,**fit_info}\n",
    "d = {**d, **to_print}\n",
    "text = nice_string_output(d, extra_spacing=2, decimals=3)\n",
    "add_text_to_ax(0.55, 0.95, text, ax, fontsize=14)\n",
    "\n",
    "x_sampled, y_sampled = sample_points(func_to_fit,minuit_fit.values[:],10000,max(counts),xmin,xmax)\n",
    "ax.scatter(x_sampled,y_sampled, s=.1, label='Uniform Sampled timings')\n",
    "\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "timing_results = pd.concat([timing_results,pd.DataFrame(np.array([row[0],row[1],row[2],func_to_fit.__name__,minuit_fit.values.to_dict()]).reshape(1,-1),columns=timing_results.columns.values)],axis=0)\n",
    "minuit_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49fe778-6405-4c04-b703-a7dab7e3ac8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(figsize=(16,5))\n",
    "counts, bins, bars = ax.hist(data, bins=Nbins, range=(xmin,xmax), histtype='step', density=False, alpha=1, color='g',label='Binned Duration Data')\n",
    "ax.errorbar(x, y, yerr=sy, xerr=0.0, label='Binned data uncertainty', fmt='.k',  ecolor='k', elinewidth=1, capsize=1, capthick=1)\n",
    "\n",
    "initial_values_dict = {\n",
    "    'N_exp':10000,\n",
    "    'tau': 1/np.e,\n",
    "    'N': 2000,\n",
    "    'mu': np.log(50),\n",
    "    'sigma': np.log(10),\n",
    "    'N2': 1000,\n",
    "    'mu2': np.log(140),\n",
    "    'sigma2': np.log(10),\n",
    "    'binwidth':binwidth\n",
    "}\n",
    "func_to_fit = double_log_gaussian_exp\n",
    "#minuit_fit = fit_ls_minuit(func_to_fit,initial_values_dict,x,y,sy)\n",
    "\n",
    "custom_initial_values_dict = {\n",
    "    'N_exp':4000,\n",
    "    'loc_exp':0,\n",
    "    'scale_exp':1,\n",
    "    'N':1000,\n",
    "    'loc':50,\n",
    "    'scale':14,\n",
    "    'N2':2000,\n",
    "    'loc2':140,\n",
    "    'scale2':10,\n",
    "    'binwidth':binwidth\n",
    "}\n",
    "\n",
    "\n",
    "def double_log_gaussian_exp(x,N_exp, tau,N,mu,sigma,N2,mu2,sigma2,binwidth):\n",
    "    return N_exp*binwidth*exp_pdf(x,tau) + N*binwidth*log_gauss_pdf(x,mu,sigma) + N2*binwidth*log_gauss_pdf(x,mu2,sigma2)\n",
    "\n",
    "# ,\n",
    "def custom_pdf(x,N_exp,loc_exp,scale_exp, N, loc, scale, N2, loc2, scale2,binwidth):\n",
    "    \"\"\"Gaussian\"\"\"\n",
    "    return N_exp*binwidth*expon.pdf(x,loc_exp,scale_exp) + \\\n",
    "            N*binwidth*norm.pdf(x, loc, scale) + \\\n",
    "            N2*binwidth*norm.pdf(x, loc2, scale2)\n",
    "Minuit.print_level = 1\n",
    "ls_fit = cost.LeastSquares(x, y, sy, func_to_fit)\n",
    "minuit_fit = Minuit(ls_fit, **initial_values_dict)\n",
    "minuit_fit.fixed['binwidth'] = True\n",
    "minuit_fit.migrad()       # Perform the actual fit\n",
    "\n",
    "ls_fit = minuit_fit.fval\n",
    "\n",
    "\n",
    "pred_y = []\n",
    "for k in x:\n",
    "    pred_y.append(func_to_fit(k, *minuit_fit.values[:]))\n",
    "pred_y = np.array(pred_y)\n",
    "ax.plot(x, pred_y, '-r',label='least squares fit')     # Note how we can \"smartly\" input the fit values!\n",
    "\n",
    "\n",
    "d = {\n",
    " 'Rule':      'DELAY',\n",
    " 'Event from':      row[1],\n",
    " 'Event to':     row[2],\n",
    "}\n",
    "to_print = {}\n",
    "to_print['Reduced chi2'] = minuit_fit.fval / (len(y) - minuit_fit.nfit)  # reduced chi2\n",
    "pm = u\"\\u00B1\"\n",
    "for k,v in minuit_fit.values.to_dict().items():\n",
    "    to_print[k] = f'{v:.2f}'+pm+f'{minuit_fit.errors.to_dict()[k]:.2f}'\n",
    "#d = {**d,**fit_info}\n",
    "d = {**d, **to_print}\n",
    "text = nice_string_output(d, extra_spacing=2, decimals=3)\n",
    "add_text_to_ax(0.45, 0.95, text, ax, fontsize=16)\n",
    "\n",
    "#x_sampled, y_sampled = sample_points(func_to_fit,minuit_fit.values[:],10000,max(counts),xmin,xmax)\n",
    "#ax.scatter(x_sampled,y_sampled, s=.1, label='Uniform Sampled timings')\n",
    "ax.set_xlabel('Duration in days')\n",
    "ax.set_ylabel('Bin counts')\n",
    "ax.set_title('Fitting a mixture distribution to the data')\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "timing_results = pd.concat([timing_results,pd.DataFrame(np.array([row[0],row[1],row[2],func_to_fit.__name__,minuit_fit.values.to_dict()]).reshape(1,-1),columns=timing_results.columns.values)],axis=0)\n",
    "minuit_fit\n",
    "plt.savefig('mixturefit_createfine_sendfine.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b81036-8984-4ea6-8ae9-ab42cc0086cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.utils.fixes import parse_version\n",
    "\n",
    "N = 100\n",
    "np.random.seed(1)\n",
    "X = np.concatenate(\n",
    "    (np.random.normal(0, 1, int(0.3 * N)), np.random.normal(5, 1, int(0.7 * N)))\n",
    ")[:, np.newaxis]\n",
    "\n",
    "X_plot = np.linspace(-5, 10, 1000)[:, np.newaxis]\n",
    "\n",
    "true_dens = 0.3 * norm(0, 1).pdf(X_plot[:, 0]) + 0.7 * norm(5, 1).pdf(X_plot[:, 0])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.fill(X_plot[:, 0], true_dens, fc=\"black\", alpha=0.2, label=\"input distribution\")\n",
    "colors = [\"navy\", \"cornflowerblue\", \"darkorange\"]\n",
    "kernels = [\"gaussian\", \"tophat\", \"epanechnikov\"]\n",
    "lw = 2\n",
    "\n",
    "for color, kernel in zip(colors, kernels):\n",
    "    kde = KernelDensity(kernel=kernel, bandwidth=0.5).fit(X)\n",
    "    log_dens = kde.score_samples(X_plot)\n",
    "    ax.plot(\n",
    "        X_plot[:, 0],\n",
    "        np.exp(log_dens),\n",
    "        color=color,\n",
    "        lw=lw,\n",
    "        linestyle=\"-\",\n",
    "        label=\"kernel = '{0}'\".format(kernel),\n",
    "    )\n",
    "\n",
    "ax.text(6, 0.38, \"N={0} points\".format(N))\n",
    "\n",
    "ax.legend(loc=\"upper left\")\n",
    "ax.plot(X[:, 0], -0.005 - 0.01 * np.random.random(X.shape[0]), \"+k\")\n",
    "\n",
    "ax.set_xlim(-4, 9)\n",
    "ax.set_ylim(-0.02, 0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503c4da2-f0c9-4ca7-b32a-9f8ebe13b9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "gm = GaussianMixture(n_components=4, random_state=0).fit(data.reshape(-1,1))\n",
    "gm.means_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e0b6ad-b5fe-4bd0-ab71-cf72d62a8d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gm.predict([[40],[110]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f6c462-09e2-4575-aa77-fa73f958dc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_ls_minuit(function_to_fit, initial_values_dict, x, y, sy, err_def=1):\n",
    "    \"\"\"Fit any defined function using least squares\n",
    "    NOTE: All fixed parameters that are part of the 'function_to_fit'\n",
    "    need to be initialized before this method call\n",
    "    \n",
    "    Parameters:\n",
    "    function_to_fit: the function to fit the data to can be anything (gaussian, exp, exp+gauss,a+b)\n",
    "    initial_values_dict: a dictionary of key value pairs that are the initial input to the function_to_fit\n",
    "    x: input training data\n",
    "    y: result training data\n",
    "    sy: errors on the output (if data is binned errors are poisson)\n",
    "    err_def: 1: ls fit 0.5: likelihood fit\n",
    "   \n",
    "    returns: Chi2, Ndof, Prob\n",
    "    \"\"\"\n",
    "    Minuit.print_level = 1\n",
    "    ls_fit = cost.LeastSquares(x, y, sy, function_to_fit)\n",
    "    minuit_fit = Minuit(ls_fit, **initial_values_dict)   \n",
    "    minuit_fit.migrad()       # Perform the actual fit\n",
    "\n",
    "    ls_fit = minuit_fit.fval\n",
    "    return minuit_fit\n",
    "\n",
    "#'norm': {'loc': 85.13093521722415, 'scale': 42.078394977302224}\n",
    "\n",
    "def N_gauss_pdf(x, N, loc, scale,binwidth):\n",
    "    \"\"\"Gaussian\"\"\"\n",
    "    return N*binwidth*norm.pdf(x, loc, scale)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16,5))\n",
    "counts, bins, bars = ax.hist(data, bins=Nbins, range=(xmin,xmax), histtype='step', density=False, alpha=1, color='g',label='Binned duration data')\n",
    "ax.errorbar(x, y, yerr=sy, xerr=0.0, label='Binned data uncertainty', fmt='.k',  ecolor='k', elinewidth=1, capsize=1, capthick=1)\n",
    "\n",
    "\n",
    "initial_values_dict = {\n",
    "    'N': 2000,\n",
    "    'loc': 85,\n",
    "    'scale': 42,\n",
    "    'binwidth':binwidth\n",
    "}\n",
    "func_to_fit = N_gauss_pdf\n",
    "#minuit_fit = fit_ls_minuit(func_to_fit,initial_values_dict,x,y,sy)\n",
    "\n",
    "Minuit.print_level = 1\n",
    "ls_fit = cost.LeastSquares(x, y, sy, func_to_fit)\n",
    "minuit_fit = Minuit(ls_fit, **initial_values_dict)\n",
    "minuit_fit.fixed['binwidth'] = True\n",
    "minuit_fit.migrad()       # Perform the actual fit\n",
    "\n",
    "ls_fit = minuit_fit.fval\n",
    "\n",
    "\n",
    "pred_y = []\n",
    "for k in x:\n",
    "    pred_y.append(func_to_fit(k, *minuit_fit.values[:]))\n",
    "pred_y = np.array(pred_y)\n",
    "ax.plot(x, pred_y, '-r',label='least squares fit')     # Note how we can \"smartly\" input the fit values!\n",
    "\n",
    "\n",
    "d = {\n",
    " 'Rule':      'DELAY',\n",
    " 'Event from':      row[1],\n",
    " 'Event to':     row[2],\n",
    "}\n",
    "to_print = {}\n",
    "to_print['Reduced chi2'] = minuit_fit.fval / (len(y) - minuit_fit.nfit)  # reduced chi2\n",
    "pm = u\"\\u00B1\"\n",
    "for k,v in minuit_fit.values.to_dict().items():\n",
    "    to_print[k] = f'{v:.2f}'+pm+f'{minuit_fit.errors.to_dict()[k]:.2f}'\n",
    "#d = {**d,**fit_info}\n",
    "d = {**d, **to_print}\n",
    "text = nice_string_output(d, extra_spacing=2, decimals=3)\n",
    "add_text_to_ax(0.45, 0.95, text, ax, fontsize=16)\n",
    "\n",
    "#x_sampled, y_sampled = sample_points(func_to_fit,minuit_fit.values[:],10000,max(counts),xmin,xmax)\n",
    "#ax.scatter(x_sampled,y_sampled, s=.1, label='Uniform Sampled timings')\n",
    "ax.set_xlabel('Duration in days')\n",
    "ax.set_ylabel('Bin counts')\n",
    "ax.set_title('Fitting one gaussian to the data')\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "timing_results = pd.concat([timing_results,pd.DataFrame(np.array([row[0],row[1],row[2],func_to_fit.__name__,minuit_fit.values.to_dict()]).reshape(1,-1),columns=timing_results.columns.values)],axis=0)\n",
    "minuit_fit\n",
    "plt.savefig('simplefit_createfine_sendfine.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ff8c15-8ad8-49f7-9f0a-1a2821da6796",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boxplot_values(data):\n",
    "    median = np.median(data)\n",
    "    upper_quartile = np.percentile(data, 75)\n",
    "    lower_quartile = np.percentile(data, 25)\n",
    "\n",
    "    iqr = upper_quartile - lower_quartile\n",
    "    upper_whisker = data[data<=upper_quartile+1.5*iqr].max()\n",
    "    lower_whisker = data[data>=lower_quartile-1.5*iqr].min()\n",
    "    min = data.min()\n",
    "    max = data.max()\n",
    "    mean = np.mean(data)\n",
    "    return (lower_whisker,lower_quartile,median,upper_quartile,upper_whisker,iqr,min,max,mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183f3db4-20c0-4fcc-b611-22d9ea72658b",
   "metadata": {},
   "source": [
    "## Descriptive statistics between Create fine and send fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82699b6c-a928-4387-90bd-50dc2b648c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nbins, _ = freedman_diaconis_rule(data)\n",
    "counts, bin_edges = np.histogram(data,bins=Nbins,range=(xmin,xmax))\n",
    "# take only non empty bins, that's why counts>0\n",
    "x = (bin_edges[1:][counts>0] + bin_edges[:-1][counts>0])/2\n",
    "y = counts[counts>0]\n",
    "sy = np.sqrt(counts[counts>0])   # NOTE: We (naturally) assume that the bin count is Poisson distributed.\n",
    "figs, axs = plt.subplots(2,1,figsize=(16,8),sharex=True)\n",
    "ax = axs[0]\n",
    "ax.boxplot(data,vert=False,flierprops={'marker':'x', 'markerfacecolor':'r', 'markersize':1})\n",
    "ax.set_xlabel('Duration (Days)')\n",
    "ax.set_ylabel('Boxplot')\n",
    "ax.set_title('DELAY: Create fine -> Send fine ')\n",
    "\n",
    "lower_whisker,lower_quartile,median,upper_quartile,upper_whisker,iqr,dmin,dmax,mean = get_boxplot_values(data)\n",
    "\n",
    "d = {'Lower whisker':lower_whisker,\n",
    "    'Lower quartile':lower_quartile,\n",
    "    'Median':median,\n",
    "    'Upper quartile':upper_quartile,\n",
    "    'Upper whisker':upper_whisker,\n",
    "    'IQR':iqr}\n",
    "text = nice_string_output(d, extra_spacing=2, decimals=3)\n",
    "add_text_to_ax(0.70, 0.95, text, ax, fontsize=16)\n",
    "\n",
    "ax = axs[1]\n",
    "ax.set(xlim=(xmin-1, xmax))\n",
    "ax.hist(data, bins=Nbins, range=(xmin, xmax), histtype='step', density=False, alpha=1, color='g',\n",
    "        label='Binned Duration Data')\n",
    "ax.errorbar(x, y, yerr=sy, xerr=0.0, label='Data, with Poisson errors', fmt='.k',  ecolor='k', elinewidth=1, capsize=1, capthick=1)\n",
    "ax.set_xlabel('Duration (Days)')\n",
    "ax.set_ylabel('Binned count')\n",
    "\n",
    "d = {\n",
    "    'Min':dmin,\n",
    "    'Max':dmax,\n",
    "    'Mean':mean}\n",
    "text = nice_string_output(d, extra_spacing=2, decimals=3)\n",
    "add_text_to_ax(0.70, 0.95, text, ax, fontsize=16)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('box_hist_create_fine_send_fine.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e6538a-03d2-4c10-96e7-9d1055a0b01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030f0c58-39fe-4623-afe6-e9f40c5e0118",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d937af-682b-4fe9-a4d1-b18245790ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f028087-5511-4667-9f09-056209340f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cebcc3c-cdcf-4ef4-a5f6-b1c1435751eb",
   "metadata": {},
   "source": [
    "## 1: CONDITION   ['Send Fine', 'Insert Fine Notification'] 79860"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e889b483-8fea-4858-bfe3-8f6133fad67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,5))\n",
    "data,Nbins,x,y,sy,row,binwidth = data_dict[1]\n",
    "counts, bins, bars = ax.hist(data, bins=Nbins, range=(xmin,xmax), histtype='step', density=False, alpha=1, color='g',label='Binned Duration Data')\n",
    "ax.errorbar(x, y, yerr=sy, xerr=0.0, label='Data, with Poisson errors', fmt='.k',  ecolor='k', elinewidth=1, capsize=1, capthick=1)\n",
    "\n",
    "initial_values_dict = {\n",
    "    'N_exp':100000,\n",
    "    'tau': 1.0,\n",
    "    'N': 2000,\n",
    "    'mu': 10,\n",
    "    'sigma': 4,\n",
    "    'N2': 1000,\n",
    "    'mu2': np.log(19),\n",
    "    'sigma2': np.log(3)\n",
    "}\n",
    "\n",
    "func_to_fit = gaus_log_gauss_exp#double_log_gaussian_exp\n",
    "\n",
    "minuit_fit = fit_minuit(func_to_fit,initial_values_dict,x,y,sy)\n",
    "\n",
    "pred_y = []\n",
    "for k in x:\n",
    "    pred_y.append(func_to_fit(k, *minuit_fit.values[:]))\n",
    "pred_y = np.array(pred_y)\n",
    "ax.plot(x, pred_y, '-r',label='chi2 fit')     # Note how we can \"smartly\" input the fit values!\n",
    "\n",
    "\n",
    "\n",
    "d = {\n",
    " 'Rule':      row[0],\n",
    " 'Event from':      row[1],\n",
    " 'Event to':     row[2],\n",
    "}\n",
    "to_print = {}\n",
    "pm = u\"\\u00B1\"\n",
    "for k,v in minuit_fit.values.to_dict().items():\n",
    "    to_print[k] = f'{v:.2f}'+pm+f'{minuit_fit.errors.to_dict()[k]:.2f}'\n",
    "d = {**d,**fit_info}\n",
    "d = {**d, **to_print}\n",
    "text = nice_string_output(d, extra_spacing=2, decimals=3)\n",
    "add_text_to_ax(0.50, 0.77, text, ax, fontsize=14)\n",
    "\n",
    "\n",
    "x_sampled, y_sampled = sample_points(func_to_fit,minuit_fit.values[:],10000,max(counts),xmin,xmax)\n",
    "ax.scatter(x_sampled,y_sampled, s=.1, label='Scatter plot of data')\n",
    "\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "timing_results = pd.concat([timing_results,pd.DataFrame(np.array([row[0],row[1],row[2],func_to_fit.__name__,minuit_fit.values.to_dict()]).reshape(1,-1),columns=timing_results.columns.values)],axis=0)\n",
    "minuit_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ffcf58-4819-4d04-a8bd-b7ac5a13bef6",
   "metadata": {},
   "source": [
    "## 2: CONDITION   ['Insert Fine Notification', 'Add penalty'] 79860"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdb6e1b-7e29-4479-8b00-e708361e442e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data,Nbins,x,y,sy,row = data_dict[2]\n",
    "timing_results = pd.concat([timing_results,pd.DataFrame(np.array([row[0],row[1],row[2],'x',{'x':60.0}]).reshape(1,-1),columns=timing_results.columns.values)],axis=0)\n",
    "print(data.min(),data.max())\n",
    "print(f'This condition is consistently {np.median(data)} days. No fit necessary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0397f647-72e7-46eb-aa82-ae7798259616",
   "metadata": {},
   "source": [
    "## 3: CONDITION   ['Create Fine', 'Add penalty'] 79860"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190a6a96-887e-4acf-8769-65dadb281af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,5))\n",
    "data,Nbins,x,y,sy,row,binwidth = data_dict[3]\n",
    "counts, bins, bars = ax.hist(data, bins=Nbins, range=(xmin,xmax), histtype='step', density=False, alpha=1, color='g',label='Binned Duration Data')\n",
    "ax.errorbar(x, y, yerr=sy, xerr=0.0, label='Data, with Poisson errors', fmt='.k',  ecolor='k', elinewidth=1, capsize=1, capthick=1)\n",
    "\n",
    "initial_values_dict = {\n",
    "    'N': 100,\n",
    "    'mu': 60,\n",
    "    'sigma': 0.5,\n",
    "    'N2': 1000,\n",
    "    'mu2': np.log(120),\n",
    "    'sigma2': np.log(15),\n",
    "    'N3': 2000,\n",
    "    'mu3': np.log(205),\n",
    "    'sigma3': np.log(20)\n",
    "}\n",
    "func_to_fit = triple_gauss_log_log\n",
    "minuit_fit, fit_info = fit_minuit(func_to_fit,initial_values_dict,x,y,sy)\n",
    "\n",
    "pred_y = []\n",
    "for k in x:\n",
    "    pred_y.append(func_to_fit(k, *minuit_fit.values[:]))\n",
    "pred_y = np.array(pred_y)\n",
    "ax.plot(x, pred_y, '-r',label='chi2 fit')     # Note how we can \"smartly\" input the fit values!\n",
    "\n",
    "\n",
    "\n",
    "d = {\n",
    " 'Rule':      row[0],\n",
    " 'Event from':      row[1],\n",
    " 'Event to':     row[2],\n",
    "}\n",
    "to_print = {}\n",
    "pm = u\"\\u00B1\"\n",
    "for k,v in minuit_fit.values.to_dict().items():\n",
    "    to_print[k] = f'{v:.2f}'+pm+f'{minuit_fit.errors.to_dict()[k]:.2f}'\n",
    "d = {**d,**fit_info}\n",
    "d = {**d, **to_print}\n",
    "text = nice_string_output(d, extra_spacing=2, decimals=3)\n",
    "add_text_to_ax(0.50, 0.77, text, ax, fontsize=14)\n",
    "\n",
    "\n",
    "x_sampled, y_sampled = sample_points(func_to_fit,minuit_fit.values[:],10000,max(counts),xmin,xmax)\n",
    "ax.scatter(x_sampled,y_sampled, s=.1, label='Scatter plot of data')\n",
    "\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "timing_results = pd.concat([timing_results,pd.DataFrame(np.array([row[0],row[1],row[2],func_to_fit.__name__,minuit_fit.values.to_dict()]).reshape(1,-1),columns=timing_results.columns.values)],axis=0)\n",
    "minuit_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649c549a-410c-48cf-a2e1-fe1dbfcc53b9",
   "metadata": {},
   "source": [
    "## 4 CONDITION   ['Add penalty', 'Send for Credit Collection'] 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7672af-833a-4aca-b1ec-de942076c38d",
   "metadata": {},
   "source": [
    "Not enough data points for making time estimates of this rule\n",
    "\n",
    "TODO: Make a mean value approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ce7595-8fec-45bd-954d-720cacc39135",
   "metadata": {},
   "source": [
    "## 5: CONDITION   ['Send Fine', 'Send for Credit Collection'] 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d39403b-0dd6-487e-954e-006dfe40e31b",
   "metadata": {},
   "source": [
    "Not enough data points for making time estimates of this rule\n",
    "\n",
    "TODO: Make a mean value approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423823ca-a4cd-44b8-a526-5718d8432754",
   "metadata": {},
   "source": [
    "## 6: CONDITION   ['Create Fine', 'Payment'] 10033"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239e93bf-8755-4a4c-a600-766c6ebfdf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,5))\n",
    "data,Nbins,x,y,sy,row,binwidth = data_dict[6]\n",
    "counts, bins, bars = ax.hist(data, bins=Nbins, range=(xmin,xmax), histtype='step', density=False, alpha=1, color='g',label='Binned Duration Data')\n",
    "ax.errorbar(x, y, yerr=sy, xerr=0.0, label='Data, with Poisson errors', fmt='.k',  ecolor='k', elinewidth=1, capsize=1, capthick=1)\n",
    "\n",
    "initial_values_dict = {\n",
    "    'N_exp':1000,\n",
    "    'tau': 1/np.e,\n",
    "    'N': 100,\n",
    "    'mu': np.log(90),\n",
    "    'sigma': np.log(10),\n",
    "    'N2': 120,\n",
    "    'mu2': np.log(190),\n",
    "    'sigma2': np.log(10),\n",
    "    'binwidth':binwidth\n",
    "}\n",
    "\n",
    "func_to_fit = double_log_gaussian_exp\n",
    "minuit_fit, fit_info = fit_minuit(func_to_fit,initial_values_dict,x,y,sy)\n",
    "\n",
    "pred_y = []\n",
    "for k in x:\n",
    "    pred_y.append(func_to_fit(k, *minuit_fit.values[:]))\n",
    "pred_y = np.array(pred_y)\n",
    "ax.plot(x, pred_y, '-r',label='chi2 fit')     # Note how we can \"smartly\" input the fit values!\n",
    "\n",
    "\n",
    "\n",
    "d = {\n",
    " 'Rule':      row[0],\n",
    " 'Event from':      row[1],\n",
    " 'Event to':     row[2],\n",
    "}\n",
    "to_print = {}\n",
    "pm = u\"\\u00B1\"\n",
    "for k,v in minuit_fit.values.to_dict().items():\n",
    "    to_print[k] = f'{v:.2f}'+pm+f'{minuit_fit.errors.to_dict()[k]:.2f}'\n",
    "d = {**d,**fit_info}\n",
    "d = {**d, **to_print}\n",
    "text = nice_string_output(d, extra_spacing=2, decimals=3)\n",
    "add_text_to_ax(0.50, 0.77, text, ax, fontsize=14)\n",
    "\n",
    "x_sampled, y_sampled = sample_points(func_to_fit,minuit_fit.values[:],10000,max(counts),xmin,xmax)\n",
    "ax.scatter(x_sampled,y_sampled, s=.1, label='Scatter plot of data')\n",
    "\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "timing_results = pd.concat([timing_results,pd.DataFrame(np.array([row[0],row[1],row[2],func_to_fit.__name__,minuit_fit.values.to_dict()]).reshape(1,-1),columns=timing_results.columns.values)],axis=0)\n",
    "minuit_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2b90bb-0452-4e09-b882-fc24de50eb23",
   "metadata": {},
   "source": [
    "## 7: CONDITION   ['Create Fine', 'Insert Date Appeal to Prefecture'] 4188"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2521d868-b2a4-42ad-82e6-2643c32e7cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,5))\n",
    "data,Nbins,x,y,sy,row,binwith = data_dict[7]\n",
    "counts, bins, bars = ax.hist(data, bins=Nbins, range=(xmin,xmax), histtype='step', density=False, alpha=1, color='g',label='Binned Duration Data')\n",
    "ax.errorbar(x, y, yerr=sy, xerr=0.0, label='Data, with Poisson errors', fmt='.k',  ecolor='k', elinewidth=1, capsize=1, capthick=1)\n",
    "\n",
    "initial_values_dict = {\n",
    "    #'N_exp':1000,\n",
    "    #'tau': 1/np.e,\n",
    "    'N': 1000,\n",
    "    'mu': 90,\n",
    "    'sigma': 10,\n",
    "    'N2': 200,\n",
    "    'mu2': 19,\n",
    "    'sigma2': 4,\n",
    "    'N3': 1200,\n",
    "    'mu3': np.log(190),\n",
    "    'sigma3':np.log(10)\n",
    "}\n",
    "\n",
    "func_to_fit = triple_gauss_gauss_log #triple_gaussian #double_log_gaussian_exp\n",
    "minuit_fit, fit_info = fit_minuit(func_to_fit,initial_values_dict,x,y,sy)\n",
    "\n",
    "pred_y = []\n",
    "for k in x:\n",
    "    pred_y.append(func_to_fit(k, *minuit_fit.values[:]))\n",
    "pred_y = np.array(pred_y)\n",
    "ax.plot(x, pred_y, '-r',label='chi2 fit')     # Note how we can \"smartly\" input the fit values!\n",
    "\n",
    "\n",
    "\n",
    "d = {\n",
    " 'Rule':      row[0],\n",
    " 'Event from':      row[1],\n",
    " 'Event to':     row[2],\n",
    "}\n",
    "to_print = {}\n",
    "pm = u\"\\u00B1\"\n",
    "for k,v in minuit_fit.values.to_dict().items():\n",
    "    to_print[k] = f'{v:.2f}'+pm+f'{minuit_fit.errors.to_dict()[k]:.2f}'\n",
    "d = {**d,**fit_info}\n",
    "d = {**d, **to_print}\n",
    "text = nice_string_output(d, extra_spacing=2, decimals=3)\n",
    "add_text_to_ax(0.50, 0.77, text, ax, fontsize=14)\n",
    "\n",
    "x_sampled, y_sampled = sample_points(func_to_fit,minuit_fit.values[:],10000,max(counts),xmin,xmax)\n",
    "ax.scatter(x_sampled,y_sampled, s=.1, label='Scatter plot of data')\n",
    "\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "timing_results = pd.concat([timing_results,pd.DataFrame(np.array([row[0],row[1],row[2],func_to_fit.__name__,minuit_fit.values.to_dict()]).reshape(1,-1),columns=timing_results.columns.values)],axis=0)\n",
    "minuit_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ad7fe5-062c-4483-84d7-2cb9328676b6",
   "metadata": {},
   "source": [
    "## 8: CONDITION   ['Create Fine', 'Send Appeal to Prefecture'] 997"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f6e16a-370d-4a65-a27d-7c61ef854237",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,5))\n",
    "data,Nbins,x,y,sy,row,binwidth = data_dict[8]\n",
    "counts, bins, bars = ax.hist(data, bins=Nbins, range=(xmin,xmax), histtype='step', density=False, alpha=1, color='g',label='Binned Duration Data')\n",
    "ax.errorbar(x, y, yerr=sy, xerr=0.0, label='Data, with Poisson errors', fmt='.k',  ecolor='k', elinewidth=1, capsize=1, capthick=1)\n",
    "\n",
    "initial_values_dict = {\n",
    "    'N': 499,\n",
    "    'mu': 120,\n",
    "    'sigma': 20,\n",
    "    'N2': 200,\n",
    "    'mu2': 200,\n",
    "    'sigma2': 10\n",
    "}\n",
    "func_to_fit = double_gaussian\n",
    "minuit_fit, fit_info = fit_minuit(func_to_fit,initial_values_dict,x,y,sy)\n",
    "\n",
    "pred_y = []\n",
    "for k in x:\n",
    "    pred_y.append(func_to_fit(k, *minuit_fit.values[:]))\n",
    "pred_y = np.array(pred_y)\n",
    "ax.plot(x, pred_y, '-r',label='chi2 fit')     # Note how we can \"smartly\" input the fit values!\n",
    "\n",
    "\n",
    "\n",
    "d = {\n",
    " 'Rule':      row[0],\n",
    " 'Event from':      row[1],\n",
    " 'Event to':     row[2],\n",
    "}\n",
    "to_print = {}\n",
    "pm = u\"\\u00B1\"\n",
    "for k,v in minuit_fit.values.to_dict().items():\n",
    "    to_print[k] = f'{v:.2f}'+pm+f'{minuit_fit.errors.to_dict()[k]:.2f}'\n",
    "d = {**d,**fit_info}\n",
    "d = {**d, **to_print}\n",
    "text = nice_string_output(d, extra_spacing=2, decimals=3)\n",
    "add_text_to_ax(0.50, 0.77, text, ax, fontsize=14)\n",
    "\n",
    "x_sampled, y_sampled = sample_points(func_to_fit,minuit_fit.values[:],10000,max(counts),xmin,xmax)\n",
    "ax.scatter(x_sampled,y_sampled, s=.1, label='Scatter plot of data')\n",
    "\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "timing_results = pd.concat([timing_results,pd.DataFrame(np.array([row[0],row[1],row[2],func_to_fit.__name__,minuit_fit.values.to_dict()]).reshape(1,-1),columns=timing_results.columns.values)],axis=0)\n",
    "minuit_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78fe487-a890-49d0-a648-72e59d4287c9",
   "metadata": {},
   "source": [
    "## 9: CONDITION   ['Send Fine', 'Receive Result Appeal from Prefecture'] 946"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48ce2fc-5377-4a60-b4d0-bfa499b621b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,5))\n",
    "data,Nbins,x,y,sy,row,binwidth = data_dict[9]\n",
    "counts, bins, bars = ax.hist(data, bins=Nbins, range=(xmin,xmax), histtype='step', density=False, alpha=1, color='g',label='Binned Duration Data')\n",
    "ax.errorbar(x, y, yerr=sy, xerr=0.0, label='Data, with Poisson errors', fmt='.k',  ecolor='k', elinewidth=1, capsize=1, capthick=1)\n",
    "\n",
    "initial_values_dict = {\n",
    "    'N':400,\n",
    "    'mu': np.log(120),\n",
    "    'sigma': np.log(40)\n",
    "}\n",
    "func_to_fit = N_log_gauss_pdf\n",
    "minuit_fit = fit_minuit(func_to_fit,initial_values_dict,x,y,sy)\n",
    "\n",
    "pred_y = []\n",
    "for k in x:\n",
    "    pred_y.append(func_to_fit(k, *minuit_fit.values[:]))\n",
    "pred_y = np.array(pred_y)\n",
    "ax.plot(x, pred_y, '-r',label='chi2 fit')     # Note how we can \"smartly\" input the fit values!\n",
    "\n",
    "\n",
    "\n",
    "d = {\n",
    " 'Rule':      row[0],\n",
    " 'Event from':      row[1],\n",
    " 'Event to':     row[2],\n",
    "}\n",
    "to_print = {}\n",
    "pm = u\"\\u00B1\"\n",
    "for k,v in minuit_fit.values.to_dict().items():\n",
    "    to_print[k] = f'{v:.2f}'+pm+f'{minuit_fit.errors.to_dict()[k]:.2f}'\n",
    "d = {**d,**fit_info}\n",
    "d = {**d, **to_print}\n",
    "text = nice_string_output(d, extra_spacing=2, decimals=3)\n",
    "add_text_to_ax(0.50, 0.77, text, ax, fontsize=14)\n",
    "\n",
    "# x_sampled, y_sampled = sample_points(func_to_fit,minuit_fit.values[:],10000,max(counts),xmin,xmax)\n",
    "# ax.scatter(x_sampled,y_sampled, s=.1, label='Scatter plot of data')\n",
    "\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "timing_results = pd.concat([timing_results,pd.DataFrame(np.array([row[0],row[1],row[2],func_to_fit.__name__,minuit_fit.values.to_dict()]).reshape(1,-1),columns=timing_results.columns.values)],axis=0)\n",
    "minuit_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65a214c-6e54-4326-ace3-e44fa6ab36eb",
   "metadata": {},
   "source": [
    "## 10: CONDITION   ['Insert Fine Notification', 'Notify Result Appeal to Offender'] 810"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04b0896-ed60-4e0d-b5e8-0a53fac9dbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,5))\n",
    "data,Nbins,x,y,sy,row,binwidth = data_dict[10]\n",
    "counts, bins, bars = ax.hist(data, bins=Nbins, range=(xmin,xmax), histtype='step', density=False, alpha=1, color='g',label='Binned Duration Data')\n",
    "ax.errorbar(x, y, yerr=sy, xerr=0.0, label='Data, with Poisson errors', fmt='.k',  ecolor='k', elinewidth=1, capsize=1, capthick=1)\n",
    "\n",
    "initial_values_dict = {\n",
    "    'N':300,\n",
    "    'mu': np.log(120),\n",
    "    'sigma': np.log(30)\n",
    "}\n",
    "func_to_fit = N_log_gauss_pdf\n",
    "minuit_fit = fit_minuit(func_to_fit,initial_values_dict,x,y,sy)\n",
    "\n",
    "pred_y = []\n",
    "for k in x:\n",
    "    pred_y.append(func_to_fit(k, *minuit_fit.values[:]))\n",
    "pred_y = np.array(pred_y)\n",
    "ax.plot(x, pred_y, '-r',label='chi2 fit')     # Note how we can \"smartly\" input the fit values!\n",
    "\n",
    "\n",
    "\n",
    "d = {\n",
    " 'Rule':      row[0],\n",
    " 'Event from':      row[1],\n",
    " 'Event to':     row[2],\n",
    "}\n",
    "to_print = {}\n",
    "pm = u\"\\u00B1\"\n",
    "for k,v in minuit_fit.values.to_dict().items():\n",
    "    to_print[k] = f'{v:.2f}'+pm+f'{minuit_fit.errors.to_dict()[k]:.2f}'\n",
    "d = {**d,**fit_info}\n",
    "d = {**d, **to_print}\n",
    "text = nice_string_output(d, extra_spacing=2, decimals=3)\n",
    "add_text_to_ax(0.50, 0.77, text, ax, fontsize=14)\n",
    "\n",
    "#x_sampled, y_sampled = sample_points(func_to_fit,minuit_fit.values[:],10000,max(counts),xmin,xmax)\n",
    "#ax.scatter(x_sampled,y_sampled, s=.1, label='Scatter plot of data')\n",
    "\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "timing_results = pd.concat([timing_results,pd.DataFrame(np.array([row[0],row[1],row[2],func_to_fit.__name__,minuit_fit.values.to_dict()]).reshape(1,-1),columns=timing_results.columns.values)],axis=0)\n",
    "minuit_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4294f6-bc74-4740-9a51-c1516b594d7b",
   "metadata": {},
   "source": [
    "## 11: CONDITION   ['Create Fine', 'Notify Result Appeal to Offender'] 810"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ca6f97-2e89-44d9-8c0f-bcb4cdd6d030",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,5))\n",
    "data,Nbins,x,y,sy,row,binwidth = data_dict[11]\n",
    "counts, bins, bars = ax.hist(data, bins=Nbins, range=(xmin,xmax), histtype='step', density=False, alpha=1, color='g',label='Binned Duration Data')\n",
    "ax.errorbar(x, y, yerr=sy, xerr=0.0, label='Data, with Poisson errors', fmt='.k',  ecolor='k', elinewidth=1, capsize=1, capthick=1)\n",
    "\n",
    "initial_values_dict = {\n",
    "    'N':200,\n",
    "    'mu': 275,\n",
    "    'sigma': 77\n",
    "}\n",
    "func_to_fit = N_gauss_pdf\n",
    "minuit_fit = fit_minuit(func_to_fit,initial_values_dict,x,y,sy)\n",
    "\n",
    "pred_y = []\n",
    "for k in x:\n",
    "    pred_y.append(func_to_fit(k, *minuit_fit.values[:]))\n",
    "pred_y = np.array(pred_y)\n",
    "ax.plot(x, pred_y, '-r',label='least squares fit')     # Note how we can \"smartly\" input the fit values!\n",
    "\n",
    "\n",
    "\n",
    "d = {\n",
    " 'Rule':      'DELAY',\n",
    " 'Event from':      row[1],\n",
    " 'Event to':     row[2],\n",
    " 'Reduced chi2': minuit_fit.fval / (len(y) - minuit_fit.nfit)  # reduced chi2\n",
    "}\n",
    "to_print = {}\n",
    "pm = u\"\\u00B1\"\n",
    "for k,v in minuit_fit.values.to_dict().items():\n",
    "    to_print[k] = f'{v:.2f}'+pm+f'{minuit_fit.errors.to_dict()[k]:.2f}'\n",
    "# d = {**d,**fit_info}\n",
    "d = {**d, **to_print}\n",
    "text = nice_string_output(d, extra_spacing=2, decimals=3)\n",
    "add_text_to_ax(0.55, 0.60, text, ax, fontsize=16)\n",
    "\n",
    "# x_sampled, y_sampled = sample_points(func_to_fit,minuit_fit.values[:],10000,max(counts),xmin,xmax)\n",
    "# ax.scatter(x_sampled,y_sampled, s=.1, label='Scatter plot of data')\n",
    "\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "ax.set_xlabel('Duration in days')\n",
    "ax.set_ylabel('Bin counts')\n",
    "ax.set_title('Fitting a single gaussian distribution to the data')\n",
    "timing_results = pd.concat([timing_results,pd.DataFrame(np.array([row[0],row[1],row[2],func_to_fit.__name__,minuit_fit.values.to_dict()]).reshape(1,-1),columns=timing_results.columns.values)],axis=0)\n",
    "minuit_fit\n",
    "plt.savefig('single_gaussian.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31d7654-f540-422d-aa9c-dd083ed75181",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88bb6f71-cf58-4ca7-97fa-fd4860904422",
   "metadata": {},
   "source": [
    "## 12: CONDITION   ['Create Fine', 'Appeal to Judge'] 421"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d02dfc1-067c-4749-9b2e-e6b0f360d467",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,5))\n",
    "data,Nbins,x,y,sy,row,binwidth = data_dict[12]\n",
    "counts, bins, bars = ax.hist(data, bins=Nbins, range=(xmin,xmax), histtype='step', density=False, alpha=1, color='g',label='Binned Duration Data')\n",
    "ax.errorbar(x, y, yerr=sy, xerr=0.0, label='Data, with Poisson errors', fmt='.k',  ecolor='k', elinewidth=1, capsize=1, capthick=1)\n",
    "\n",
    "initial_values_dict = {\n",
    "    'N_exp':1000,\n",
    "    'tau': 1/np.e,\n",
    "    'N': 100,\n",
    "    'mu': np.log(150),\n",
    "    'sigma': np.log(50),\n",
    "    'N2': 200,\n",
    "    'mu2': np.log(200),\n",
    "    'sigma2': np.log(10),\n",
    "    'binwidth':binwidth\n",
    "}\n",
    "func_to_fit = double_log_gaussian_exp\n",
    "minuit_fit, fit_info = fit_minuit(func_to_fit,initial_values_dict,x,y,sy)\n",
    "\n",
    "pred_y = []\n",
    "for k in x:\n",
    "    pred_y.append(func_to_fit(k, *minuit_fit.values[:]))\n",
    "pred_y = np.array(pred_y)\n",
    "ax.plot(x, pred_y, '-r',label='chi2 fit')     # Note how we can \"smartly\" input the fit values!\n",
    "\n",
    "\n",
    "\n",
    "d = {\n",
    " 'Rule':      row[0],\n",
    " 'Event from':      row[1],\n",
    " 'Event to':     row[2],\n",
    "}\n",
    "to_print = {}\n",
    "pm = u\"\\u00B1\"\n",
    "for k,v in minuit_fit.values.to_dict().items():\n",
    "    to_print[k] = f'{v:.2f}'+pm+f'{minuit_fit.errors.to_dict()[k]:.2f}'\n",
    "d = {**d,**fit_info}\n",
    "d = {**d, **to_print}\n",
    "text = nice_string_output(d, extra_spacing=2, decimals=3)\n",
    "add_text_to_ax(0.50, 0.77, text, ax, fontsize=14)\n",
    "\n",
    "# x_sampled, y_sampled = sample_points(func_to_fit,minuit_fit.values[:],10000,max(counts),xmin,xmax)\n",
    "# ax.scatter(x_sampled,y_sampled, s=.1, label='Scatter plot of data')\n",
    "\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "timing_results = pd.concat([timing_results,pd.DataFrame(np.array([row[0],row[1],row[2],func_to_fit.__name__,minuit_fit.values.to_dict()]).reshape(1,-1),columns=timing_results.columns.values)],axis=0)\n",
    "minuit_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e02c36d-7ac9-4f25-8665-622b3797174a",
   "metadata": {},
   "source": [
    "## 13: RESPONSE   ['Insert Fine Notification', 'Add penalty'] 79860"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26021e14-58eb-42a0-b381-f845a2fc855b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,2))\n",
    "data,Nbins,x,y,sy,row,binwidth = data_dict[13]\n",
    "ax.hist(data, bins=Nbins, range=(xmin,xmax), histtype='step', density=False, alpha=1, color='g',label='Binned Duration Data')\n",
    "ax.errorbar(x, y, yerr=sy, xerr=0.0, label='Data, with Poisson errors', fmt='.k',  ecolor='k', elinewidth=1, capsize=1, capthick=1)\n",
    "ax.set(xlim=(0,800))\n",
    "print(data.min(),data.max())\n",
    "timing_results = pd.concat([timing_results,pd.DataFrame(np.array([row[0],row[1],row[2],'x',{'x':60.0}]).reshape(1,-1),columns=timing_results.columns.values)],axis=0)\n",
    "print(f'This response is consistently {np.median(data)} days. No fit necessary')\n",
    "ax.set_xlabel('Duration in days')\n",
    "ax.set_ylabel('Bin counts')\n",
    "add_text_to_ax(0.50, 0.77, 'Single bin at 60 days', ax, fontsize=16)\n",
    "ax.set_title('Single bin histogram for Deadline: Insert Fine Notification -> Add penalty')\n",
    "plt.savefig('single_bin_example.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4451b6-3633-4a2f-96bc-1c7e5e404ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nbins, _ = freedman_diaconis_rule(data)\n",
    "counts, bin_edges = np.histogram(data,bins=Nbins,range=(xmin,xmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e174f69e-290f-4644-9fa7-1af05d99771c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(counts[counts>0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bd1e77-18c8-4dc3-9ff7-c118c793891d",
   "metadata": {},
   "source": [
    "# Create a sampling algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f963cce7-dd2f-4b29-bb7b-52e336a59985",
   "metadata": {},
   "source": [
    "* Sample a given number of traces from all possible events of length N where N is a random number between the minimum and maximum length trace\n",
    "* Do accept/reject sampling to only allow traces that do not violate the dcr rules mined from the original data\n",
    "* For the remaining traces randomly sample from the timing distributions (if no specialised timing distribution exists then sample from a normal distribution/exponential)\n",
    "* Repeat until a given number of traces has been achieved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9f2676-4f99-4b38-9762-82006aefaece",
   "metadata": {},
   "outputs": [],
   "source": [
    "timing_results = timing_results.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e549c52-8c94-4108-b64f-fdc6b0ed787a",
   "metadata": {},
   "outputs": [],
   "source": [
    "timing_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b3c77b-002b-40e5-9601-2ce95fedeb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_trace(trace, graph):\n",
    "    return null\n",
    "\n",
    "def replay_trace(trace, graph):\n",
    "    return null\n",
    "\n",
    "def creater_synthetic_log(graph):\n",
    "    return null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b93b6f3-d08a-437b-a693-a81c101efb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_response(trace):\n",
    "    return null\n",
    "\n",
    "def check_condition(trace):\n",
    "    return null\n",
    "\n",
    "def check_include(trace):\n",
    "    return null\n",
    "\n",
    "def check_exclude(trace):\n",
    "    return null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a804c588-c434-49dd-8157-b821b3a9cb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_timing_between_events(event1, event2):\n",
    "    return null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd64ace2-2c04-4c1e-a87e-90f229b8ecf0",
   "metadata": {},
   "source": [
    "set of total events\n",
    "\n",
    "set of conditioned events based on current event\n",
    "\n",
    "set of response events based on current event\n",
    "\n",
    "set of include events based on current event\n",
    "\n",
    "set of exclude events based on current event\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e034a826-e6e2-45ce-907f-d20b67d3fa0a",
   "metadata": {},
   "source": [
    "# Check the probability distributions of the DCR timed rules mined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c93d216-84ee-4efc-8ab9-bfadab684a57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81098e7b-c5b0-4f69-ba00-5f188fae479f",
   "metadata": {},
   "source": [
    "## Where there is a mixture split the event log according to the mixture\n",
    "+ find a way to automatically detect the mixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefdbd43-56a7-4689-a8f9-f5eb2b767c28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3044d158-2cef-46c2-bfbd-c84c53ac6f4d",
   "metadata": {},
   "source": [
    "# Split traces where events (and event subsets) are either observed or unobserved based on specific events.\n",
    "\n",
    "Make a dataset dictionary based on the investigated (rule, event pair) + the set of observed/unobserved events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bd0eb4-5832-4055-8b3d-3b4e3485db6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = all_timings[['Rule','Event1','Event2']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b7159b-5fda-453a-a0bc-324546fc6fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "events = list(activities.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519ea055-3a1d-4fac-b584-f092a474ec29",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee635a38-e9e2-4af3-94bf-ffd7fbcf948b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_splits = {}\n",
    "for rule in rules:\n",
    "    print('[i] investigating ',rule)\n",
    "    subset_events = events.copy()\n",
    "    subset_events.remove(rule[1])\n",
    "    subset_events.remove(rule[2])\n",
    "    all_subsets = subset_events\n",
    "    #all_subsets = list(chain(*map(lambda x: combinations(subset_events, x), range(1, len(subset_events)+1))))\n",
    "    i=1\n",
    "    for filtered_events in all_subsets:\n",
    "        print('[i] at ',i,' of ',len(all_subsets))\n",
    "        i = i+1\n",
    "        log_unobserved = attributes_filter.apply(log, negative_events,\n",
    "                                          parameters={attributes_filter.Parameters.ATTRIBUTE_KEY: \"concept:name\", \n",
    "                                                      attributes_filter.Parameters.POSITIVE: False})\n",
    "        log_observed = attributes_filter.apply(log, negative_events,\n",
    "                                          parameters={attributes_filter.Parameters.ATTRIBUTE_KEY: \"concept:name\", \n",
    "                                                      attributes_filter.Parameters.POSITIVE: True})\n",
    "        dataset_splits[str(np.append(rule,[filtered_events,'unobserved']))] = log_unobserved\n",
    "        dataset_splits[str(np.append(rule,[filtered_events,'observed']))] = log_observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93cb912-f88f-4b59-8b61-2e49775e9da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in dataset_splits.items():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0d359e-b722-46e7-a8c2-223da06511fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_events = ['Send for Credit Collection','Send Appeal to Prefecture']\n",
    "log_filtered (unobserved) = attributes_filter.apply(log, negative_events,\n",
    "                                          parameters={attributes_filter.Parameters.ATTRIBUTE_KEY: \"concept:name\", attributes_filter.Parameters.POSITIVE: False})\n",
    "log_unfiltered (observed) = attributes_filter.apply(log, negative_events,\n",
    "                                          parameters={attributes_filter.Parameters.ATTRIBUTE_KEY: \"concept:name\", attributes_filter.Parameters.POSITIVE: True})\n",
    "\n",
    "event_log_pos = log_converter.apply(log_pos, variant=log_converter.Variants.TO_DATA_FRAME)\n",
    "event_log_neg = log_converter.apply(log_neg, variant=log_converter.Variants.TO_DATA_FRAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dabc3a-58ba-4120-abe8-647f789c21dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_events = ['Send for Credit Collection','Send Appeal to Prefecture']\n",
    "log_pos = attributes_filter.apply(log, negative_events,\n",
    "                                          parameters={attributes_filter.Parameters.ATTRIBUTE_KEY: \"concept:name\", attributes_filter.Parameters.POSITIVE: False})\n",
    "log_neg = attributes_filter.apply(log, negative_events,\n",
    "                                          parameters={attributes_filter.Parameters.ATTRIBUTE_KEY: \"concept:name\", attributes_filter.Parameters.POSITIVE: True})\n",
    "event_log_pos = log_converter.apply(log_pos, variant=log_converter.Variants.TO_DATA_FRAME)\n",
    "event_log_neg = log_converter.apply(log_neg, variant=log_converter.Variants.TO_DATA_FRAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2993e6ed-ec12-4be1-9621-950202dca6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(log) == len(log_pos)+len(log_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad994564-4bdb-4acf-92fe-61cc7872f42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(log_pos))\n",
    "print(len(log_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04c237c-5604-4aea-85e0-e2c116955166",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_dataset = \"/c/Data/road_traffic_fine/log_pos.xes\"\n",
    "pos_model = '../models/road_traffic_fine_pos'\n",
    "pos_timing_results = '../models/timing_information_pos.csv'\n",
    "neg_dataset = \"/c/Data/road_traffic_fine/log_neg.xes\"\n",
    "neg_model = '../models/road_traffic_fine_neg'\n",
    "neg_timing_results = '../models/timing_information_neg.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77f626a-cb9d-4ec5-ae30-1a0ca0185a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm4py.objects.log.exporter.xes.exporter.apply(log_pos, pos_dataset)\n",
    "pm4py.objects.log.exporter.xes.exporter.apply(log_neg, neg_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696f5dac-10a9-4138-9e90-639992519656",
   "metadata": {},
   "outputs": [],
   "source": [
    "dcrt.create_timings(pos_dataset,pos_model,pos_timing_results)\n",
    "dcrt.create_timings(neg_dataset,neg_model,neg_timing_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50031adf-4a7a-4ed8-8f1c-b77e70bbadb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_timings = pd.read_csv(pos_timing_results)\n",
    "neg_timings = pd.read_csv(neg_timing_results)\n",
    "\n",
    "all_timings['Discriminator'] = 'All'\n",
    "neg_timings['Discriminator'] = 'Neg'\n",
    "pos_timings['Discriminator'] = 'Pos'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9fa424-4cde-4bff-b37d-4dedb3ad548f",
   "metadata": {},
   "source": [
    "# Analyze results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0526679-3fc8-4267-8ca5-ce5e3fc54c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.concat([all_timings, neg_timings, pos_timings]).sort_values(['Rule','Event1','Event2','Discriminator']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fa907b-0d3b-4c6f-aa14-9337e6dacaf2",
   "metadata": {},
   "source": [
    "## Look at Create Fine -> Payment durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1294512a-b263-4167-ba6f-786b2a7f5406",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_pair = ['Create Fine','Payment']\n",
    "create_to_pay = res[(res['Rule']=='CONDITION') & (res['Event1']==event_pair[0]) & (res['Event2']==event_pair[1])]\n",
    "create_to_pay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3ee197-1dc8-4d00-b6da-4252e0850ae7",
   "metadata": {},
   "source": [
    "## All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c3f446-575f-4e4d-9908-b92b58cd6c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_timing_data(get_delta_between_events(log,event_pair))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29768d4b-2583-4e0b-945c-c315f9d7b2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_from_lognorm(create_to_pay[create_to_pay['Discriminator']=='All'][['lognorm_shape','lognorm_loc','lognorm_scale']].values.reshape(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db41af67-adca-4eb0-a5dd-26b105654f2a",
   "metadata": {},
   "source": [
    "## Neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03381e8-98cc-4dd9-a37d-970f8d783523",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_timing_data(get_delta_between_events(log_neg,event_pair))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821398c3-7f25-45ba-bd42-ddce7a80cfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_from_lognorm(create_to_pay[create_to_pay['Discriminator']=='Neg'][['lognorm_shape','lognorm_loc','lognorm_scale']].values.reshape(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431228d6-d6b0-41af-83be-dd52118f109c",
   "metadata": {},
   "source": [
    "## Pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6140e1a3-537d-4565-b359-7705d2bc2250",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_timing_data(get_delta_between_events(log_pos,event_pair))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bd815d-2dc4-47f7-bb1b-eb7eb1cf8694",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_from_lognorm(create_to_pay[create_to_pay['Discriminator']=='Pos'][['lognorm_shape','lognorm_loc','lognorm_scale']].values.reshape(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81dda4d-2ad2-4ca6-9566-cf8fd40abee7",
   "metadata": {},
   "source": [
    "# Timings basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330a493b-af88-4002-b3af-73c134ca614c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_with_pair(event_log,e1,e2):\n",
    "    first_e1 = event_log[event_log['concept:name']==e1].groupby('case:concept:name')[['case:concept:name','time:timestamp']].first().reset_index(drop=True)\n",
    "    subset_is_in = first_e1.merge(event_log,on='case:concept:name',how='inner',suffixes=('_e1', ''))\n",
    "    cids = subset_is_in[((subset_is_in['time:timestamp_e1']<subset_is_in['time:timestamp']) & (subset_is_in['concept:name']==e2))]['case:concept:name'].unique()\n",
    "    return event_log[event_log['case:concept:name'].isin(cids)].copy(deep=True)\n",
    "\n",
    "def get_max_for_response(temp_df):    \n",
    "    cid=None\n",
    "    max_days = 0\n",
    "    for index,row in temp_df.iterrows():\n",
    "        if cid == row['case:concept:name'] or cid==None:\n",
    "            max_days = max(max_days,row['delta'])\n",
    "            if row['concept:name']!=row['concept:name:to']:\n",
    "                #print(max_days,' row: ',row)\n",
    "                temp_df.loc[index,'delta'] = max_days\n",
    "                max_days = 0\n",
    "        cid = row['case:concept:name']\n",
    "\n",
    "    return temp_df\n",
    "\n",
    "def get_delta_between_events(filtered_log, event_pair, rule):\n",
    "    if isinstance(filtered_log,pd.DataFrame):\n",
    "        filtered_df = filtered_log\n",
    "    else:\n",
    "        filtered_df = log_converter.apply(filtered_log, variant=log_converter.Variants.TO_DATA_FRAME)\n",
    "    \n",
    "    filtered_df['time:timestamp'] = pd.to_datetime(filtered_df['time:timestamp'], utc=True)\n",
    "    filtered_df = filtered_df[(filtered_df['concept:name']==event_pair[1]) | \n",
    "                               (filtered_df['concept:name']==event_pair[0])].sort_values(['case:concept:name','time:timestamp'])\n",
    "    temp_df = pd.concat([filtered_df, filtered_df.groupby('case:concept:name').shift(-1)\n",
    "                         .rename({'concept:name':'concept:name:to','time:timestamp':'time:timestamp:to'},axis=1)],axis=1)\n",
    "                         \n",
    "    temp_df['delta'] = (temp_df['time:timestamp:to'] - temp_df['time:timestamp']).dt.days\n",
    "        \n",
    "    if rule=='RESPONSE':\n",
    "        temp_df = get_max_for_response(temp_df)\n",
    "    temp_df = temp_df[(temp_df['concept:name']==event_pair[0]) & (temp_df['concept:name:to']==event_pair[1])]\n",
    "    data = temp_df['delta'].values\n",
    "    return data\n",
    "\n",
    "def create_timing_input_dict(model):\n",
    "    with open(model) as file:\n",
    "        lines = file.readlines()\n",
    "        lines = [line.strip() for line in lines]\n",
    "\n",
    "    events = []\n",
    "    conditions = []\n",
    "    responses = []\n",
    "    #includes = []\n",
    "    #excludes = []\n",
    "    for line in lines:\n",
    "        temp = line.split(',')\n",
    "        if temp[0] == 'EVENT':\n",
    "            events.append(temp[1])\n",
    "        elif temp[0] == 'CONDITION':\n",
    "            conditions.append(temp[1:])\n",
    "        elif temp[0] == 'RESPONSE':\n",
    "            responses.append(temp[1:])\n",
    "\n",
    "    timing_input_dict = {'CONDITION' : conditions,\n",
    "                         'RESPONSE': responses}\n",
    "    return timing_input_dict\n",
    "\n",
    "def get_timings(event_log,timing_input_dict):\n",
    "    res = {}\n",
    "\n",
    "    for rule, event_pairs in timing_input_dict.items():\n",
    "        #print(rule)\n",
    "        for event_pair in event_pairs:\n",
    "            filtered_df = get_log_with_pair(event_log,event_pair[0],event_pair[1]) #= pm4py.filter_between(log,event_pair[0],event_pair[1])\n",
    "            data = get_delta_between_events(filtered_df,event_pair,rule)\n",
    "            #print(event_pair)\n",
    "            res[(rule,event_pair[0],event_pair[1])] = data\n",
    "            \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f088fb4-024c-48c4-9a71-c87ccad8b87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset ='/c/Data/road_traffic_fine/Road_Traffic_Fine_Management_Process.xes'\n",
    "model = '/c/Projects/DisCoveR-JS/models/road_traffic_fine'\n",
    "timing_results = '../models/timing_information.csv'\n",
    "    \n",
    "with open(model) as file:\n",
    "    lines = file.readlines()\n",
    "    lines = [line.strip() for line in lines]\n",
    "\n",
    "events = []\n",
    "conditions = []\n",
    "responses = []\n",
    "#includes = []\n",
    "#excludes = []\n",
    "for line in lines:\n",
    "    temp = line.split(',')\n",
    "    if temp[0] == 'EVENT':\n",
    "        events.append(temp[1])\n",
    "    elif temp[0] == 'CONDITION':\n",
    "        conditions.append(temp[1:])\n",
    "    elif temp[0] == 'RESPONSE':\n",
    "        responses.append(temp[1:])\n",
    "\n",
    "timing_input_dict = {'CONDITION' : conditions,\n",
    "                     'RESPONSE': responses}\n",
    "\n",
    "#log = pm4py.read_xes(dataset)\n",
    "#event_log = log_converter.apply(log, variant=log_converter.Variants.TO_DATA_FRAME)\n",
    "#timing = pd.DataFrame(columns=['Rule','Event1','Event2','bins','boxplot'])\n",
    "\n",
    "res = {}\n",
    "\n",
    "for rule, event_pairs in timing_input_dict.items():\n",
    "    print(rule)\n",
    "    for event_pair in event_pairs:\n",
    "        filtered_df = get_log_with_pair(event_log,event_pair[0],event_pair[1]) #= pm4py.filter_between(log,event_pair[0],event_pair[1])\n",
    "        data = get_delta_between_events(filtered_df,event_pair,rule)\n",
    "        print(event_pair)\n",
    "        res[f'{rule} ({event_pair[0]}, {event_pair[1]})'] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775da30e-e271-487e-9c13-3ba01185e75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_potential_conditions = []\n",
    "all_potential_responses = []\n",
    "for e1 in events:\n",
    "    for e2 in events:\n",
    "        all_potential_conditions.append([e1,e2])\n",
    "        all_potential_responses.append([e1,e2])\n",
    "        \n",
    "all_potential_timings = {'CONDITION': all_potential_conditions,\n",
    "                        'RESPONSE': all_potential_responses}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7361fea9-f3f5-4cfa-af15-a1353a8dcf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for rule, event_pairs in all_potential_timings.items():\n",
    "    print(rule)\n",
    "    for event_pair in event_pairs:        \n",
    "        filtered_df = get_log_with_pair(event_log,event_pair[0],event_pair[1]) #= pm4py.filter_between(log,event_pair[0],event_pair[1])\n",
    "        data = get_delta_between_events(filtered_df,event_pair,rule)\n",
    "        print(event_pair)\n",
    "        res[f'{rule} ({event_pair[0]}, {event_pair[1]})'] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6312af-33b2-4310-ada4-78c622d00808",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_log_with_pair(e1,e2,event_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1ac497-bcd8-4e01-bb55-437d003f5a3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16394365-891b-47b6-9622-43c03c1d29d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094cbb58-5528-455c-9a11-dfd78dd9b24a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4d5784-5804-4531-af9f-9fd53ceef1cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f93b7bd-116d-40da-8e11-11da3a3f5762",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_converter.apply(temp, variant=log_converter.Variants.TO_DATA_FRAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb4ef7e-bc6d-4cdd-acc8-e12046a5b693",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(len(res)*2,1,figsize=(16,100),sharex=True)\n",
    "i = 0\n",
    "fitted_summaries = {}\n",
    "for label, data in res.items():\n",
    "    print(i)\n",
    "    if i not in [3,4,5]:\n",
    "        data,Nbins,x,y,sy,row = data_dict[i]\n",
    "        \n",
    "        f = Fitter(data,distributions=get_common_distributions())\n",
    "        f.fit()\n",
    "        fitter_summary_df = f.summary(plot=False)\n",
    "        print(fitter_summary_df)\n",
    "        fitted_summaries[label] = fitter_summary_df\n",
    "        axs[2*i].set_title(label)\n",
    "        axs[2*i].hist(data, bins=Nbins, range=(xmin,xmax), histtype='step', density=False, alpha=1, color='g',label='Binned Duration Data')\n",
    "        axs[2*i].errorbar(x, y, yerr=sy, xerr=0.0, label='Data, with Poisson errors', fmt='.k',  ecolor='k', elinewidth=1, capsize=1, capthick=1)\n",
    "        \n",
    "        \n",
    "        axs[2*i+1].boxplot(data,vert=False,flierprops={'marker':'x', 'markerfacecolor':'r', 'markersize':1})\n",
    "    i += 1\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb27a80-0cfc-469c-8dc8-543abb5d01f5",
   "metadata": {},
   "source": [
    "# Create a potential matrix for all conditions and responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088ae416-aa18-4ded-83f1-611d0502bb6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
