{
 "cells": [
  {
   "cell_type": "code",
   "id": "263f80b5fb10dad1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-02T09:38:52.908336Z",
     "start_time": "2025-08-02T09:38:52.897771Z"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "22315afb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-02T09:38:53.478409Z",
     "start_time": "2025-08-02T09:38:53.249176Z"
    }
   },
   "source": [
    "import os\n",
    "os.chdir(os.path.dirname(os.getcwd()))\n",
    "os.getcwd()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/vco/Projects/delay-deadline-miner'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-02T09:38:54.327440Z",
     "start_time": "2025-08-02T09:38:53.622476Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "import pm4py\n",
    "from pm4py.algo.discovery.dcr_discover.extenstions.nesting import NestVariants\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-02T09:50:13.311661Z",
     "start_time": "2025-08-02T09:50:13.293372Z"
    }
   },
   "cell_type": "code",
   "source": "from notebook.ebda_util import *",
   "id": "cc9488a8e87b6b88",
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "id": "a048e562fe78d6c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-02T09:40:21.911533Z",
     "start_time": "2025-08-02T09:40:21.881936Z"
    }
   },
   "source": [
    "from pm4py.objects.conversion.log import converter as log_converter\n",
    "import pandas as pd\n",
    "\n",
    "cids = [1, 1, 1, 1, 1,\n",
    "        2, 2, 2, 2, 2,\n",
    "        3, 3, 3, 3,\n",
    "        4, 4, 4, 4, 4]\n",
    "events = ['Doctor requests home care', 'Send mail', 'Consent', 'Assessment', 'Approved',\n",
    "          'Doctor requests home care', 'Send mail', 'Consent', 'Assessment', 'Denied',\n",
    "          'Citizen requests home care', 'Consent', 'Assessment', 'Approved',\n",
    "          'Citizen requests home care', 'Consent', 'Assessment', 'Assessment', 'Denied']\n",
    "timestamps = [pd.to_datetime('2025-01-01'), pd.to_datetime('2025-01-02'), pd.to_datetime('2025-01-09'),\n",
    "              pd.to_datetime('2025-01-10'), pd.to_datetime('2025-01-17'),\n",
    "              pd.to_datetime('2025-01-01'), pd.to_datetime('2025-01-07'), pd.to_datetime('2025-01-18'),\n",
    "              pd.to_datetime('2025-04-01'), pd.to_datetime('2025-04-05'),\n",
    "              pd.to_datetime('2025-01-01'), pd.to_datetime('2025-01-07'), pd.to_datetime('2025-01-15'),\n",
    "              pd.to_datetime('2025-01-21'),\n",
    "              pd.to_datetime('2025-01-01'), pd.to_datetime('2025-01-05'), pd.to_datetime('2025-01-20'),\n",
    "              pd.to_datetime('2025-01-27'), pd.to_datetime('2025-02-01')]\n",
    "\n",
    "test_log_dict = {\n",
    "    'case:concept:name': cids,\n",
    "    'concept:name': events,\n",
    "    'time:timestamp': timestamps\n",
    "}\n",
    "test_log_df = pd.DataFrame(test_log_dict)\n",
    "test_event_log = log_converter.apply(test_log_df)\n",
    "\n",
    "cids = [1, 1, 1, 1, 1,\n",
    "        2, 2, 2, 2, 2,\n",
    "        3, 3, 3, 3,\n",
    "        4, 4, 4, 4, 4]\n",
    "events = ['Request', 'Send mail', 'Consent', 'Assessment', 'Decision',\n",
    "          'Request', 'Send mail', 'Consent', 'Assessment', 'Decision',\n",
    "          'Request', 'Consent', 'Assessment', 'Decision',\n",
    "          'Request', 'Consent', 'Assessment', 'Assessment', 'Decision']\n",
    "timestamps = [pd.to_datetime('2025-01-01'), pd.to_datetime('2025-01-02'), pd.to_datetime('2025-01-09'),\n",
    "              pd.to_datetime('2025-01-10'), pd.to_datetime('2025-01-17'),\n",
    "              pd.to_datetime('2025-01-01'), pd.to_datetime('2025-01-07'), pd.to_datetime('2025-01-18'),\n",
    "              pd.to_datetime('2025-04-01'), pd.to_datetime('2025-04-05'),\n",
    "              pd.to_datetime('2025-01-01'), pd.to_datetime('2025-01-07'), pd.to_datetime('2025-01-15'),\n",
    "              pd.to_datetime('2025-01-21'),\n",
    "              pd.to_datetime('2025-01-01'), pd.to_datetime('2025-01-05'), pd.to_datetime('2025-01-20'),\n",
    "              pd.to_datetime('2025-01-27'), pd.to_datetime('2025-02-01')]\n",
    "\n",
    "test_log_dict = {\n",
    "    'case:concept:name': cids,\n",
    "    'concept:name': events,\n",
    "    'time:timestamp': timestamps\n",
    "}\n",
    "test_abstracted_log_df = pd.DataFrame(test_log_dict)\n",
    "test_abstracted_log = log_converter.apply(test_abstracted_log_df)"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-02T09:40:22.196770Z",
     "start_time": "2025-08-02T09:40:22.176274Z"
    }
   },
   "cell_type": "code",
   "source": [
    "abstraction_dict = {\n",
    "    'Request': {'Doctor requests home care', 'Citizen requests home care'},\n",
    "    'Decision': {'Approved', 'Denied'}\n",
    "}\n",
    "\n",
    "abstracted_log_df = abstract_events(test_log_df, abstraction_dict)"
   ],
   "id": "5514dcc172e728dc",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-02T09:40:22.704550Z",
     "start_time": "2025-08-02T09:40:22.685395Z"
    }
   },
   "cell_type": "code",
   "source": "abstracted_log_df",
   "id": "17bc63b4f1104b48",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    case:concept:name concept:name time:timestamp\n",
       "0                   1      Request     2025-01-01\n",
       "1                   1    Send mail     2025-01-02\n",
       "2                   1      Consent     2025-01-09\n",
       "3                   1   Assessment     2025-01-10\n",
       "4                   1     Decision     2025-01-17\n",
       "5                   2      Request     2025-01-01\n",
       "6                   2    Send mail     2025-01-07\n",
       "7                   2      Consent     2025-01-18\n",
       "8                   2   Assessment     2025-04-01\n",
       "9                   2     Decision     2025-04-05\n",
       "10                  3      Request     2025-01-01\n",
       "11                  3      Consent     2025-01-07\n",
       "12                  3   Assessment     2025-01-15\n",
       "13                  3     Decision     2025-01-21\n",
       "14                  4      Request     2025-01-01\n",
       "15                  4      Consent     2025-01-05\n",
       "16                  4   Assessment     2025-01-20\n",
       "17                  4   Assessment     2025-01-27\n",
       "18                  4     Decision     2025-01-30"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case:concept:name</th>\n",
       "      <th>concept:name</th>\n",
       "      <th>time:timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Request</td>\n",
       "      <td>2025-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Send mail</td>\n",
       "      <td>2025-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Consent</td>\n",
       "      <td>2025-01-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Assessment</td>\n",
       "      <td>2025-01-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Decision</td>\n",
       "      <td>2025-01-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>Request</td>\n",
       "      <td>2025-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>Send mail</td>\n",
       "      <td>2025-01-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>Consent</td>\n",
       "      <td>2025-01-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>Assessment</td>\n",
       "      <td>2025-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>Decision</td>\n",
       "      <td>2025-04-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>Request</td>\n",
       "      <td>2025-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>Consent</td>\n",
       "      <td>2025-01-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>Assessment</td>\n",
       "      <td>2025-01-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>Decision</td>\n",
       "      <td>2025-01-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>Request</td>\n",
       "      <td>2025-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>Consent</td>\n",
       "      <td>2025-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>Assessment</td>\n",
       "      <td>2025-01-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>Assessment</td>\n",
       "      <td>2025-01-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>Decision</td>\n",
       "      <td>2025-01-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-02T09:50:19.246539Z",
     "start_time": "2025-08-02T09:50:19.032021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "timed_original_dcr, _ = pm4py.discover_dcr(test_event_log, post_process={'timed'})\n",
    "# nesting_original_dcr, _ = pm4py.discover_dcr(test_event_log, post_process={'nesting'},nest_variant=NestVariants.CHOICE)\n",
    "original_dcr, _ = pm4py.discover_dcr(test_event_log, post_process={'nesting','timed'},nest_variant=NestVariants.CHOICE)\n",
    "abstracted_dcr, _ = pm4py.discover_dcr(test_abstracted_log, post_process={'nesting','timed'},nest_variant=NestVariants.CHOICE)"
   ],
   "id": "53a085dc12f93506",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-02T09:50:19.410477Z",
     "start_time": "2025-08-02T09:50:19.393362Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rename_map = {\"Choice1\": \"Decision\", \"Choice2\": \"Request\"}\n",
    "renamed_dcr = rename_events_in_dcr_graph(original_dcr, rename_map)"
   ],
   "id": "d094ffed747b5b2c",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-02T09:50:19.764521Z",
     "start_time": "2025-08-02T09:50:19.742551Z"
    }
   },
   "cell_type": "code",
   "source": "merged_dcr = merge_dcr_graphs(renamed_dcr, abstracted_dcr)",
   "id": "1e626fdeeddc04ac",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-02T09:50:20.274583Z",
     "start_time": "2025-08-02T09:50:20.256211Z"
    }
   },
   "cell_type": "code",
   "source": [
    "timed_original_dcr = handle_timed_condition_subprocess(timed_original_dcr)\n",
    "original_dcr = handle_timed_condition_subprocess(original_dcr)\n",
    "abstracted_dcr = handle_timed_condition_subprocess(abstracted_dcr)\n",
    "merged_dcr = handle_timed_condition_subprocess(merged_dcr)"
   ],
   "id": "4f87f17f4895b46e",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-02T09:50:21.558346Z",
     "start_time": "2025-08-02T09:50:21.527729Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pm4py.objects.dcr.exporter import exporter as dcr_exporter\n",
    "\n",
    "parameters = {\"time_precision\":\"D\"}\n",
    "\n",
    "dcr_exporter.apply(timed_original_dcr,\n",
    "                   '/home/vco/Projects/delay-deadline-miner/models/timed_original_dcr.xml',**parameters)\n",
    "dcr_exporter.apply(original_dcr,\n",
    "                   '/home/vco/Projects/delay-deadline-miner/models/original_dcr.xml',**parameters)\n",
    "dcr_exporter.apply(abstracted_dcr,\n",
    "                   '/home/vco/Projects/delay-deadline-miner/models/abstracted_dcr.xml',**parameters)\n",
    "dcr_exporter.apply(merged_dcr,\n",
    "                   '/home/vco/Projects/delay-deadline-miner/models/merged_dcr.xml',**parameters)"
   ],
   "id": "4777963b585bc4c7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vco/Projects/delay-deadline-miner/pm4py/objects/dcr/exporter/variants/xml_simple.py:29: FutureWarning: 'S' is deprecated and will be removed in a future version, please use 's' instead.\n",
      "  if time.floor(freq='S').to_numpy() > 0:\n",
      "/home/vco/Projects/delay-deadline-miner/pm4py/objects/dcr/exporter/variants/xml_simple.py:31: FutureWarning: 'S' is deprecated and will be removed in a future version, please use 's' instead.\n",
      "  iso_time = time.floor(freq='S').isoformat()\n",
      "/home/vco/Projects/delay-deadline-miner/pm4py/objects/dcr/exporter/variants/xml_simple.py:45: FutureWarning: 'S' is deprecated and will be removed in a future version, please use 's' instead.\n",
      "  if time.floor(freq='S').to_numpy() > 0:\n",
      "/home/vco/Projects/delay-deadline-miner/pm4py/objects/dcr/exporter/variants/xml_simple.py:47: FutureWarning: 'S' is deprecated and will be removed in a future version, please use 's' instead.\n",
      "  iso_time = time.floor(freq='S').isoformat()\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "id": "866a566ac6896d4f",
   "metadata": {},
   "source": [
    "# Overall idea and selling point\n",
    "Mine time as the minimum delay and maximum deadline.\n",
    "Mine the lifecycle of activities.\n",
    "Mine choices.\n",
    "Create time aware subprocesses by finding patterns:\n",
    "- Self exclude, condition: required to respect timed execution semantics\n",
    "- Conditions and responses between steps in the transition lifecycle for activites: The activity subprocess\n",
    "Abstract away based on subprocesses:\n",
    "- Remove individual choices and mine the step of making a choice: downside, the individual delays/deadlines or consequences of a choice are removed. Only the effect of making a choice is kept.\n",
    "- Remove the lifecycle transition that is not equal to complete: downside, the individual effects of lifecycle transitions are not visible.\n",
    "Merge the abstract log and original log: best of both worlds. see the effect of the subprocess but also the effect of the individual event."
   ]
  },
  {
   "cell_type": "code",
   "id": "ee27b7c281a631bd",
   "metadata": {},
   "source": [
    "log_metadata = pd.read_csv('/home/vco/Datasets/Collection_Event_Logs/Metadata.csv')\n",
    "log_metadata.columns = log_metadata.columns.str.replace(r\"[\\s\\t\\n]+\", \"\", regex=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ea55b61a6edabfa2",
   "metadata": {},
   "source": [
    "log_metadata"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ee5cd0779428a6f9",
   "metadata": {},
   "source": [
    "suitable_logs = log_metadata[log_metadata['AdditionalAttributes'].str.contains('Lifecycle Transition', na=False)]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ac574ff0126e8656",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "# Clean base name\n",
    "base_name = (\n",
    "    suitable_logs['EventLogName']\n",
    "    .str.replace(' ', '_', regex=False)\n",
    "    .str.replace(',', '', regex=False)\n",
    ")\n",
    "\n",
    "# Append dataset name only if not NaN\n",
    "dataset_part = suitable_logs['EventLogDatasetFileName'].fillna('')\n",
    "dataset_part = np.where(dataset_part != '', '_' + dataset_part, '')\n",
    "\n",
    "# Conditionally add DatasetFormat only if not already in EventLogDatasetFileName\n",
    "add_format = ~suitable_logs.apply(\n",
    "    lambda row: str(row['DatasetFormat']) in str(row['EventLogDatasetFileName']),\n",
    "    axis=1\n",
    ")\n",
    "format_part = np.where(add_format, suitable_logs['DatasetFormat'], '')\n",
    "\n",
    "# Final column assignment\n",
    "suitable_logs['EventLogFileName'] = base_name + dataset_part + format_part\n",
    "\n",
    "suitable_logs_list = suitable_logs['EventLogFileName'].tolist()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "33464560798b77a9",
   "metadata": {},
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "# Load list of suitable filenames\n",
    "valid_filenames = set(sorted(suitable_logs_list))\n",
    "\n",
    "# List and filter .xes files\n",
    "xes_file_paths = glob.glob('/home/vco/Datasets/Collection_Event_Logs/*.xes')\n",
    "xes_file_paths = [os.path.abspath(p) for p in xes_file_paths]\n",
    "print(sorted(xes_file_paths))\n",
    "xes_file_paths = [p for p in xes_file_paths if os.path.basename(p) in valid_filenames]\n",
    "\n",
    "# List and filter .csv files, excluding Metadata.csv\n",
    "csv_file_paths = glob.glob('/home/vco/Datasets/Collection_Event_Logs/*.csv')\n",
    "csv_file_paths = [p for p in csv_file_paths if not p.endswith('Metadata.csv')]\n",
    "csv_file_paths = [os.path.abspath(p) for p in csv_file_paths]\n",
    "csv_file_paths = [p for p in csv_file_paths if os.path.basename(p) in valid_filenames]\n",
    "\n",
    "# Print results\n",
    "print(\"Filtered .xes files:\")\n",
    "print(xes_file_paths)\n",
    "\n",
    "print(\"Filtered .csv files:\")\n",
    "print(csv_file_paths)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9002f363a12d7736",
   "metadata": {},
   "source": [
    "suitable_logs_list.remove('BPI_Challenge_2012.csv')\n",
    "suitable_logs_list.append('BPI_Challenge_2012.xes')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5137fcc9c0aa3",
   "metadata": {},
   "source": [
    "sorted(suitable_logs_list)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7172c7c7f70d3dc",
   "metadata": {},
   "source": [
    "xes_file_paths"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "947fecaf64fb5dfb",
   "metadata": {},
   "source": [
    "# log = pm4py.read_xes('/home/vco/Projects/pm4py-dcr4py/tests/input_data/roadtraffic50traces.xes')\n",
    "log = pm4py.read_xes('/home/vco/Datasets/Road_Traffic_Fine_Management_Process.xes.gz')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "df62a02ff1ed9465",
   "metadata": {},
   "source": [
    "sepsis = \"Sepsis_Cases_Event_Log.xes\"\n",
    "log = pm4py.read_xes(f'/home/vco/Datasets/{sepsis}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d0eb39fa8ed7af96",
   "metadata": {},
   "source": [
    "log = pm4py.read_xes('/home/vco/Datasets/Collection_Event_Logs/BPI_Challenge_2012.xes')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f3487e3685ad7165",
   "metadata": {},
   "source": [
    "all_events = set(log['concept:name'].unique())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3259d085151c00d8",
   "metadata": {},
   "source": [
    "events_with_detailed_lifecycles = set()\n",
    "subset_logs_for_event = {}\n",
    "for event in all_events:\n",
    "    subset_log = log[log['concept:name']==event][['case:concept:name','lifecycle:transition','time:timestamp']]\n",
    "    lifecycle_transitions = subset_log['lifecycle:transition'].unique()\n",
    "    if len(lifecycle_transitions) > 1:\n",
    "        print(event, lifecycle_transitions)\n",
    "        events_with_detailed_lifecycles.add(event)\n",
    "        subset_log.rename({'lifecycle:transition':'concept:name'},axis=1,inplace=True)\n",
    "        subset_logs_for_event[event] = subset_log"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "58054a9f3d5e8439",
   "metadata": {},
   "source": [
    "only_complete_lifecycle_log = log[log['lifecycle:transition']=='COMPLETE']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6c4da0fa9024477",
   "metadata": {},
   "source": [
    "only_complete_lifecycle_log"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "eab9a2b0fa0e317c",
   "metadata": {},
   "source": [
    "lifecycle_graphs_for_event = {}\n",
    "for event, subset_log in subset_logs_for_event.items():\n",
    "    graph, timings = pm4py.discover_dcr(subset_log, post_process={'timed'})\n",
    "    lifecycle_graphs_for_event[event] = graph"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1d4632635533ba96",
   "metadata": {},
   "source": [
    "for event, graph in lifecycle_graphs_for_event.items():\n",
    "    print(event)\n",
    "    pm4py.view_dcr(graph)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "63be230513c82215",
   "metadata": {},
   "source": [
    "from copy import deepcopy"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5f6523f51d3c508a",
   "metadata": {},
   "source": [
    "domain_knowledge_abstraction_log = deepcopy(log)\n",
    "domain_knowledge_abstraction_log['concept:name'] = domain_knowledge_abstraction_log['concept:name'].apply(\n",
    "    lambda x: x.split('_')[0])\n",
    "subprocess_graph, subprocess_timings = pm4py.discover_dcr(domain_knowledge_abstraction_log, post_process={'timed'})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b7d037077a89da2f",
   "metadata": {},
   "source": [
    "pm4py.view_dcr(subprocess_graph)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "40ccb58c87642d95",
   "metadata": {},
   "source": [
    "lifecycle_in_event_log = deepcopy(log)\n",
    "lifecycle_in_event_log['concept:name'] = lifecycle_in_event_log['concept:name'] + '+' + lifecycle_in_event_log['lifecycle:transition']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "52689e64dca0e74b",
   "metadata": {},
   "source": [
    "lifecycle_in_event_graph, _ = pm4py.discover_dcr(lifecycle_in_event_log, post_process={'nesting','timed'},nest_variant=NestVariants.CHOICE)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ea73de7c1f658e1c",
   "metadata": {},
   "source": [
    "graph, timings = pm4py.discover_dcr(log,post_process={'nesting','timed'},nest_variant=NestVariants.CHOICE)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c0e7b58386cb6bd8",
   "metadata": {},
   "source": [
    "lifecycle_in_event_graph = handle_timed_condition_subprocess(lifecycle_in_event_graph)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "34254ceb33de5ade",
   "metadata": {},
   "source": [
    "graph = handle_timed_condition_subprocess(graph)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "894dc1a3ace1a3b7",
   "metadata": {},
   "source": [
    "def lifecycle_graph_update(graph,lifecycle_graphs_for_event,subprocess_graph):\n",
    "    events_by_prefix = {\n",
    "        sp_prefix: set([e for e in graph.events if e.startswith(sp_prefix)])\n",
    "        for sp_prefix in ['A', 'W', 'O']\n",
    "    }\n",
    "    # events_by_prefix['O'].remove('O_SENT')\n",
    "    graph.events = graph.events.union(set(['A', 'W', 'O']))\n",
    "    graph.labels = graph.labels.union(set(['A', 'W', 'O']))\n",
    "    graph.label_map['A'] = 'A'\n",
    "    graph.label_map['W'] = 'W'\n",
    "    graph.label_map['O'] = 'O'\n",
    "    graph.conditions = {**graph.conditions, **subprocess_graph.conditions}\n",
    "    graph.timedconditions = {**graph.timedconditions, **subprocess_graph.timedconditions}\n",
    "    graph.marking.included = graph.marking.included.union(set(['A', 'W', 'O']))\n",
    "    graph.subprocesses = {**graph.subprocesses, **events_by_prefix}\n",
    "    for lf_subprocess, lf_graph in lifecycle_graphs_for_event.items():\n",
    "        graph.events.add(lf_subprocess)\n",
    "        graph.labels.add(lf_subprocess)\n",
    "        graph.label_map[lf_subprocess] = lf_subprocess\n",
    "        graph.marking.included.add(lf_subprocess)\n",
    "        graph.subprocesses[lf_subprocess] = set([f\"{lf_subprocess}+{e}\" for e in lf_graph.events])\n",
    "        graph.timedconditions = {**graph.timedconditions, **lf_graph.timedconditions}\n",
    "        graph.conditions = {**graph.conditions, **lf_graph.conditions}\n",
    "        graph.responses = {**graph.responses, **lf_graph.responses}\n",
    "        graph.includes = {**graph.includes, **lf_graph.includes}\n",
    "        graph.excludes = {**graph.excludes, **lf_graph.excludes}\n",
    "    return graph"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d97bc6d3344dd17e",
   "metadata": {},
   "source": [
    "graph"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a358a795d6423081",
   "metadata": {},
   "source": [
    "lifecycle_in_event_graph = lifecycle_graph_update(lifecycle_in_event_graph,lifecycle_graphs_for_event,subprocess_graph)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "89db4c89111846aa",
   "metadata": {},
   "source": [
    "from pm4py.objects.dcr.exporter import exporter as dcr_exporter\n",
    "dcr_exporter.apply(lifecycle_in_event_graph, '/home/vco/Projects/delay-deadline-miner/models/lifecycle_in_event_graph2.xml')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ad1da496c9df4b88",
   "metadata": {},
   "source": [
    "# LLM labels my subprocesses"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "from http.client import responses\n",
    "import json\n",
    "import pandas as pd\n",
    "from openai import OpenAI, AzureOpenAI\n",
    "import json\n",
    "from itertools import product\n",
    "\n",
    "class LLMSubprocessLabeler(object):\n",
    "\n",
    "    azure_client = AzureOpenAI(\n",
    "        azure_endpoint=\"https://gdprscenariosoai.openai.azure.com/\",\n",
    "        api_key=\"9d28285b90864a218981162f600a2661\",\n",
    "        api_version=\"2024-08-01-preview\"\n",
    "    )\n",
    "\n",
    "    def __init__(self):\n",
    "        json_answer = {\n",
    "          \"label\": \"\"\n",
    "        }\n",
    "        self.system_prompt = f\"\"\"You return a single word label for the subprocess. ONLY WRITE THE ANSWER!!! ALWAYS RETURN THE ANSWER IN THE JSON OBJECT SPECIFIED:\n",
    "        {json_answer}\"\"\"\n",
    "\n",
    "    def create_user_prompt(self,\n",
    "                    subprocess_activities_list = [],\n",
    "                    preceded_list = [],\n",
    "                    succeeded_list = [],\n",
    "                ):\n",
    "        no_of_activities = len(subprocess_activities_list)\n",
    "        preceded = f\"\"\" They are preceded by {preceded_list}.\"\"\" if len(preceded_list) > 0 else \"\"\n",
    "        succeeded = f\"\"\" They are succeeded by {succeeded_list}.\"\"\" if len(succeeded_list) > 0 else \"\"\n",
    "        json_answer = {\n",
    "          \"label\": \"\"\n",
    "        }\n",
    "        prompt = f\"\"\"\n",
    "        In a process model I have {no_of_activities} activities labeled: {subprocess_activities_list}.{preceded}{succeeded} As much as possible try to provide a single word label.\n",
    "        Create a label for the subprocess which contains the {no_of_activities} activities. ONLY WRITE THE ANSWER!!! ALWAYS RETURN THE ANSWER IN THIS JSON OBJECT:\n",
    "        {json_answer}\n",
    "        \"\"\"\n",
    "        return prompt\n",
    "\n",
    "    def get_llm_answer(self, input_prompt):\n",
    "        completion = self.azure_client.chat.completions.create(\n",
    "        model=\"gpt-35-turbo\",\n",
    "        messages=[\n",
    "                {\"role\": \"system\", \"content\": self.system_prompt},\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": input_prompt\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        res = completion.choices[0].message.to_json()\n",
    "        return json.loads(res)['content']\n",
    "\n",
    "chat = LLMSubprocessLabeler()\n",
    "input_prompt = chat.create_user_prompt(original_dcr.nestedgroups['Choice1'],original_dcr.conditions['Choice1'])\n",
    "res = chat.get_llm_answer(input_prompt)\n",
    "input_prompt_2 = chat.create_user_prompt(original_dcr.nestedgroups['Choice2'])\n",
    "res_2 = chat.get_llm_answer(input_prompt_2)"
   ],
   "id": "2b2cd4dfd31021df",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e8a1bd8336248492",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "51635a33f948a2fb",
   "metadata": {},
   "source": [
    "# Old Code"
   ]
  },
  {
   "cell_type": "code",
   "id": "d9a611e8710a920a",
   "metadata": {},
   "source": [
    "# from copy import deepcopy\n",
    "#\n",
    "# import pandas as pd\n",
    "# from typing import Optional, Any, Union, Dict\n",
    "# import pm4py\n",
    "# from pm4py.objects.dcr.obj import DcrGraph\n",
    "# from pm4py.util import exec_utils, constants, xes_constants\n",
    "# from pm4py.objects.dcr.timed.obj import TimedDcrGraph\n",
    "# from pm4py.objects.log.obj import EventLog\n",
    "#\n",
    "# class TimeMining:\n",
    "#     \"\"\"\n",
    "#     The TimeMining provides a simple algorithm to mine timing data of an event log for DCR graphs\n",
    "#\n",
    "#     After initialization, user can call mine(log, G, parameters), which will return a DCR Graph with time.\n",
    "#\n",
    "#     Attributes\n",
    "#     ----------\n",
    "#     graph: Dict[str,Any]\n",
    "#\n",
    "#     Methods\n",
    "#     -------\n",
    "#     mine(log, G, parameters)\n",
    "#\n",
    "#     Notes\n",
    "#     ------\n",
    "#     *\n",
    "#     \"\"\"\n",
    "#     def __init__(self):\n",
    "#         self.idx_list = []\n",
    "#         self.timing_dict = {\"conditionsForDelays\": {}, \"responseToDeadlines\": {}}\n",
    "#\n",
    "#\n",
    "#     def get_log_with_pair(self, event_log, e1, e2):\n",
    "#         '''\n",
    "#         when selecting the case ids (cids) here there is a difference when taking\n",
    "#         strictly less than < and strictly less than or equal <=\n",
    "#         Less than or equal <= allows for instant executions (so a time of 0 between events e1 and e2)\n",
    "#         '''\n",
    "#         first_e1 = event_log[event_log['concept:name'] == e1].groupby('case:concept:name')[\n",
    "#             ['case:concept:name', 'time:timestamp']].first().reset_index(drop=True)\n",
    "#         subset_is_in = first_e1.merge(event_log, on='case:concept:name', how='inner', suffixes=('_e1', ''))\n",
    "#         cids = subset_is_in[\n",
    "#             ((subset_is_in['time:timestamp_e1'] <= subset_is_in['time:timestamp']) & (subset_is_in['concept:name'] == e2))][\n",
    "#             'case:concept:name'].unique()\n",
    "#         return event_log[event_log['case:concept:name'].isin(cids)].copy(deep=True)\n",
    "#\n",
    "#\n",
    "#     def get_delta_between_events(self, filtered_df, event_pair, rule=None):\n",
    "#         e1 = event_pair[0]\n",
    "#         e2 = event_pair[1]\n",
    "#         filtered_df = filtered_df[['case:concept:name', 'concept:name', 'time:timestamp']]\n",
    "#         filtered_df = filtered_df[filtered_df['concept:name'].isin(event_pair)]\n",
    "#         filtered_df['time:timestamp'] = pd.to_datetime(filtered_df['time:timestamp'], utc=True)\n",
    "#         deltas = []\n",
    "#         deltas_map = {}\n",
    "#         # for idx, g in filtered_df[filtered_df['concept:name'].isin([e1, e2])].groupby('case:concept:name'):\n",
    "#         for idx, g in filtered_df.groupby('case:concept:name'):\n",
    "#             g = g.sort_values(by='time:timestamp').reset_index(drop=True)\n",
    "#             g['time:timestamp:to'] = g['time:timestamp'].shift(-1)\n",
    "#             g['concept:name:to'] = g['concept:name'].shift(-1)\n",
    "#             temp_df = deepcopy(g)\n",
    "#             res = []\n",
    "#             if rule == 'RESPONSE':\n",
    "#                 g_e1 = deepcopy(g[g['concept:name'] == e1])\n",
    "#                 if len(g_e1) >= 1:\n",
    "#                     g_e1 = g_e1.reset_index(drop=False)\n",
    "#                     g_e1['index_below'] = g_e1['index'].shift(-1)\n",
    "#                     g_e1 = g_e1[((g_e1['index_below'] - g_e1['index']) == 1)]\n",
    "#                     g_e1['delta'] = g_e1['time:timestamp:to'] - g_e1['time:timestamp']\n",
    "#                     res.extend(g_e1['delta'])\n",
    "#                 temp_df = temp_df[\n",
    "#                     (temp_df['concept:name'] == e1) & (temp_df['concept:name:to'] == e2)]\n",
    "#                 temp_df['delta'] = temp_df['time:timestamp:to'] - temp_df['time:timestamp']\n",
    "#                 res.extend(temp_df['delta'])\n",
    "#             elif rule == 'CONDITION':\n",
    "#                 temp_df = temp_df[\n",
    "#                     (temp_df['concept:name'] == e1) & (temp_df['concept:name:to'] == e2)]\n",
    "#                 temp_df['delta'] = temp_df['time:timestamp:to'] - temp_df['time:timestamp']\n",
    "#                 res.extend(temp_df['delta'])\n",
    "#             else:\n",
    "#                 temp_df = temp_df[\n",
    "#                     (temp_df['concept:name'] == e1) & (temp_df['concept:name:to'] == e2)]\n",
    "#                 temp_df['delta'] = temp_df['time:timestamp:to'] - temp_df['time:timestamp']\n",
    "#                 res.extend(temp_df['delta'])\n",
    "#             deltas.extend(res)\n",
    "#             for i in set(res):\n",
    "#                 if i not in deltas_map:\n",
    "#                     deltas_map[i] = set()\n",
    "#                 deltas_map[i].add(idx)\n",
    "#         return deltas, deltas_map\n",
    "#\n",
    "#\n",
    "#     def get_filter_map(self, log: Union[pd.DataFrame, EventLog], graph):\n",
    "#         # perform mining on event logs\n",
    "#         if not isinstance(log, pd.DataFrame):\n",
    "#             log = pm4py.convert_to_dataframe(log)\n",
    "#         activities = log['case:concept:name'].unique()\n",
    "#         print(log.index)\n",
    "#\n",
    "#         timing_input_dict = {'CONDITION': set(), 'RESPONSE': set()}\n",
    "#         for e1 in graph.conditions.keys():\n",
    "#             for e2 in graph.conditions[e1]:\n",
    "#                 timing_input_dict['CONDITION'].add((e2, e1))\n",
    "#\n",
    "#         for e1 in graph.responses.keys():\n",
    "#             for e2 in graph.responses[e1]:\n",
    "#                 timing_input_dict['RESPONSE'].add((e1, e2))\n",
    "#\n",
    "#         res_filter_map = {}\n",
    "#         timings = {}\n",
    "#         for rule, event_pairs in timing_input_dict.items():\n",
    "#             for event_pair in event_pairs:\n",
    "#                 if event_pair[0] in activities and event_pair[1] in activities:\n",
    "#                     data, filter_map = self.get_timings_one_relation(log,event_pair[0], event_pair[1], rule)\n",
    "#                     timings[(rule, event_pair[0], event_pair[1])] = data\n",
    "#                     res_filter_map[(rule, event_pair[0], event_pair[1])] = filter_map\n",
    "#\n",
    "#         return timings, res_filter_map\n",
    "#\n",
    "#     def get_timings_one_relation(self,log, e1, e2, rule):\n",
    "#         filtered_df = self.get_log_with_pair(log, e1, e2)\n",
    "#         data, filter_map = self.get_delta_between_events(filtered_df, (e1,e2), rule)\n",
    "#         return data, filter_map"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f346f8fdfef85084",
   "metadata": {},
   "source": [
    "# tm = TimeMining()\n",
    "# tm.get_filter_map(log,graph)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pm4py-dcr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
